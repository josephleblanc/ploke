[
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  },
  {
    "prompt_idx": 0,
    "prompt": "Please look at the `state_manager` and `try_main` and find ways we might make it more efficient.",
    "snippet_info": [
      {
        "name": "try_main",
        "dist": 1.0687007904052734,
        "snippet": "pub async fn try_main() -> color_eyre::Result<()> {\n    dotenvy::dotenv().ok();\n\n    let mut config = config::Config::builder()\n        .add_source(\n            config::File::with_name(\n                &dirs::config_dir()\n                    .unwrap() // TODO: add error handling\n                    .join(\"ploke/config.toml\")\n                    .to_string_lossy(),\n            )\n            .required(false),\n        )\n        .add_source(config::Environment::default().separator(\"_\"))\n        .build()?\n        .try_deserialize::<crate::user_config::Config>()\n        .unwrap_or_else(|_| crate::user_config::Config::default());\n\n    // Merge curated defaults with user overrides\n    config.registry = config.registry.with_defaults();\n\n    // Apply API keys from environment variables to all providers\n    // config.registry.load_api_keys();\n    tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n    let new_db = ploke_db::Database::init_with_schema()?;\n    let db_handle = Arc::new(new_db);\n\n    // Initial parse is now optional - user can run indexing on demand\n    // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n    // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n    // spawning state meager below.\n    let io_handle = ploke_io::IoManagerHandle::new();\n\n    // TODO: These numbers should be tested for performance under different circumstances.\n    let event_bus_caps = EventBusCaps {\n        realtime_cap: 100,\n        background_cap: 1000,\n        error_cap: 100,\n        index_cap: 1000,\n    };\n    let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n    let processor = config.load_embedding_processor()?;\n    let proc_arc = Arc::new(processor);\n\n    // TODO:\n    // 1 Implement the cancellation token propagation in IndexerTask\n    // 2 Add error handling for embedder initialization failures\n    let indexer_task = IndexerTask::new(\n        db_handle.clone(),\n        io_handle.clone(),\n        Arc::clone(&proc_arc), // Use configured processor\n        CancellationToken::new().0,\n        8,\n    );\n\n    let state = Arc::new(AppState {\n        chat: ChatState::new(ChatHistory::new()),\n        config: ConfigState::default(),\n        system: SystemState::default(),\n        indexing_state: RwLock::new(None), // Initialize as None\n        indexer_task: Some(Arc::new(indexer_task)),\n        indexing_control: Arc::new(Mutex::new(None)),\n        db: db_handle,\n        embedder: Arc::clone(&proc_arc),\n        io_handle: io_handle.clone(),\n    });\n\n    // Create command channel with backpressure\n    let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n    let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n    let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n    tokio::spawn(context_manager.run());\n\n    let (cancellation_token, cancel_handle) = CancellationToken::new();\n    let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n    let file_manager = FileManager::new(\n        io_handle.clone(),\n        event_bus.subscribe(EventPriority::Background),\n        event_bus.background_tx.clone(),\n        rag_event_tx.clone(),\n        event_bus.realtime_tx.clone(),\n    );\n\n    tokio::spawn(file_manager.run());\n\n    // Spawn state manager first\n    tokio::spawn(state_manager(\n        state.clone(),\n        cmd_rx,\n        event_bus.clone(),\n        rag_event_tx,\n    ));\n\n    // Set global event bus for error handling\n    set_global_event_bus(event_bus.clone()).await;\n\n    // Spawn subsystems with backpressure-aware command sender\n    let command_style = config.command_style;\n    tokio::spawn(llm_manager(\n        event_bus.subscribe(EventPriority::Background),\n        state.clone(),\n        cmd_tx.clone(), // Clone for each subsystem\n    ));\n    tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n    let terminal = ratatui::init();\n    let app = App::new(command_style, state, cmd_tx, &event_bus, default_model());\n    let result = app.run(terminal).await;\n    ratatui::restore();\n    result\n}"
      },
      {
        "name": "test_concurrency_with_fuzzing",
        "dist": 1.2002750635147095,
        "snippet": "#[tokio::test]\n    async fn test_concurrency_with_fuzzing() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let mut rng = rand::rng();\n\n        // Send 50 pairs of commands with random delays\n        for i in 0..50 {\n            let delay_ms = rng.random_range(5..=20);\n            sleep(Duration::from_millis(delay_ms)).await;\n\n            let user_msg_id = Uuid::new_v4();\n            let embed_msg_id = Uuid::new_v4();\n            let (tx, rx) = oneshot::channel();\n\n            // Send both commands\n            cmd_tx\n                .send(StateCommand::AddUserMessage {\n                    content: format!(\"message {}\", i),\n                    new_msg_id: user_msg_id,\n                    completion_tx: tx,\n                })\n                .await\n                .unwrap();\n\n            cmd_tx\n                .send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: rx,\n                    // TODO: Revisit and update this test\n                    scan_rx: oneshot::channel().1, // dummy\n                })\n                .await\n                .unwrap();\n        }\n\n        tokio::time::sleep(Duration::from_millis(500)).await;\n\n        // Verify all messages were processed\n        let chat = state.chat.0.read().await;\n        let messages = chat.messages.len();\n        assert!(messages >= 50, \"Should have processed at least 50 messages\");\n    }"
      },
      {
        "name": "test_race_condition_without_oneshot",
        "dist": 1.2085793018341064,
        "snippet": "#[tokio::test]\n    async fn test_race_condition_without_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        // Simulate sending both commands concurrently without synchronization\n        let tx1 = cmd_tx.clone();\n        let tx2 = cmd_tx.clone();\n\n        tokio::join!(\n            async {\n                tx1.send(StateCommand::AddUserMessage {\n                    content: \"tell me a haiku\".to_string(),\n                    new_msg_id: user_msg_id,\n                    completion_tx: oneshot::channel().0, // dummy\n                })\n                .await\n                .unwrap();\n            },\n            async {\n                tx2.send(StateCommand::EmbedMessage {\n                    new_msg_id: embed_msg_id,\n                    completion_rx: oneshot::channel().1, // dummy\n                    scan_rx: oneshot::channel().1,       // dummy\n                })\n                .await\n                .unwrap();\n            }\n        );\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        // Check if the embed message read the user message or not\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should be present\"\n        );\n    }"
      },
      {
        "name": "test_fix_with_oneshot",
        "dist": 1.2183969020843506,
        "snippet": "#[tokio::test]\n    async fn test_fix_with_oneshot() {\n        let db = Database::new_init().unwrap();\n        let state = Arc::new(AppState::new(\n            Arc::new(db),\n            Arc::new(EmbeddingProcessor::mock()),\n            IoManagerHandle::mock(),\n        ));\n        let (cmd_tx, cmd_rx) = mpsc::channel(32);\n        let event_bus = Arc::new(EventBus::new(EventBusCaps::default()));\n\n        // Start state manager\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            mpsc::channel(32).0,\n        ));\n\n        let parent_id = Uuid::new_v4();\n        let user_msg_id = Uuid::new_v4();\n        let embed_msg_id = Uuid::new_v4();\n\n        let (tx, rx) = oneshot::channel();\n\n        cmd_tx\n            .send(StateCommand::AddUserMessage {\n                content: \"tell me a haiku\".to_string(),\n                new_msg_id: user_msg_id,\n                completion_tx: tx,\n            })\n            .await\n            .unwrap();\n\n        cmd_tx\n            .send(StateCommand::EmbedMessage {\n                new_msg_id: embed_msg_id,\n                completion_rx: rx,\n                // TODO: revisit this test\n                scan_rx: oneshot::channel().1, // dummy\n            })\n            .await\n            .unwrap();\n\n        tokio::time::sleep(Duration::from_millis(100)).await;\n\n        let chat = state.chat.0.read().await;\n        let last_user_msg = chat.last_user_msg();\n        assert!(\n            last_user_msg.is_ok_and(|m| m.is_some_and(|im| !im.1.is_empty())),\n            \"User message should always be present\"\n        );\n    }"
      },
      {
        "name": "save_db",
        "dist": 1.2269346714019775,
        "snippet": "pub(super) async fn save_db(state: &Arc<AppState>, event_bus: &Arc<EventBus>) -> ControlFlow<()> {\n    let default_dir = if let Ok(dir) = dirs::config_local_dir().ok_or_else(|| {\n        ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir {\n            msg: \"Could not locate default config directory on system\",\n        })\n        .emit_warning()\n    }) {\n        dir.join(\"ploke\").join(\"data\")\n    } else {\n        return ControlFlow::Break(());\n    };\n    if let Err(e) = tokio::fs::create_dir_all(&default_dir).await {\n        let msg = format!(\n            \"Error:\nCould not create directory at default location: {}\nEncountered error while finding or creating directory: {}\",\n            default_dir.display(),\n            e\n        );\n        tracing::error!(msg);\n        event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n            file_dir: format!(\"{}\", default_dir.display()),\n            is_success: false,\n            error: Some(msg),\n        }));\n    }\n    let system_guard = state.system.read().await;\n    // TODO: This error handling feels really cumbersome, should rework.\n\n    // make sure directory exists, otherwise report error\n\n    // Using crate focus here, which we set when we perform indexing.\n    // TODO: Revisit this design. Consider how to best allow for potential switches in\n    // focus of the user's target crate within the same session.\n    // - Explicit command?\n    // - Model-allowed tool calling?\n    if let Some(crate_focus) = system_guard\n        .crate_focus.clone()\n        .iter()\n        .filter_map(|cr| cr.file_name())\n        .filter_map(|cr| cr.to_str())\n        .next()\n    {\n        // let crate_focus_str = crate_focus.to_string_lossy();\n        let crate_name_version = if let Ok(db_result) = state\n            .db\n            .get_crate_name_id(crate_focus)\n            .map_err(ploke_error::Error::from)\n            .inspect_err(|e| {\n                e.emit_warning();\n            }) {\n            db_result\n        } else {\n            return ControlFlow::Break(());\n        };\n\n        let file_dir = default_dir.join(crate_name_version);\n        tracing::info!(\"Checking for previous database file {}\", file_dir.display());\n        if let Ok(mut read_dir) = std::fs::read_dir(&default_dir) {\n            tracing::info!(\"reading dir result\n{:?}\", read_dir);\n            while let Some(Ok(file)) = read_dir.next() {\n                if file.path() == file_dir {\n                    let _ = std::fs::remove_file(&file_dir).inspect_err(|e| {\n                        tracing::error!(\"Error removing previous database file {}\", file_dir.display());\n                    });\n                }\n            }\n        }\n        // TODO: Clones are bad. This is bad code. Fix it.\n        // - Wish I could blame the AI but its all me :( in a rush\n        match state.db.backup_db(file_dir.clone()) {\n            Ok(()) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: true,\n                    error: None,\n                }));\n            }\n            Err(e) => {\n                event_bus.send(AppEvent::System(SystemEvent::BackupDb {\n                    file_dir: format!(\"{}\", file_dir.display()),\n                    is_success: false,\n                    error: Some(e.to_string()),\n                }));\n            }\n        };\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "embedding_search_similar",
        "dist": 1.251373052597046,
        "snippet": "/// Performs semantic search using the provided message embedding and sends results to the context manager.\n///\n/// This function takes a vector embedding of a user message and searches the database for similar\n/// code snippets based on semantic similarity. The search results are processed into human-readable\n/// snippets and sent to the context manager for inclusion in the conversation context.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and I/O handles\n/// * `context_tx` - Channel sender for communicating with the context manager\n/// * `new_msg_id` - UUID of the message being processed (used for correlation)\n/// * `embeddings` - Vector embedding of the user's message for similarity search\n///\n/// # Process\n///\n/// 1. Searches the database for similar function nodes using the provided embedding\n/// 2. Retrieves actual code snippets for the matching nodes via I/O manager\n/// 3. Sends snippets to context manager via `RagEvent::ContextSnippets`\n/// 4. Retrieves conversation history and triggers context construction\n///\n/// # Returns\n///\n/// Returns `Ok(())` on success, or an error if any step fails\nasync fn embedding_search_similar(\n    state: &Arc<AppState>,\n    context_tx: &mpsc::Sender<RagEvent>,\n    new_msg_id: Uuid,\n    embeddings: Vec<f32>,\n) -> color_eyre::Result<()> {\n    let ty_embed_data =\n        search_similar(&state.db, embeddings.clone(), 100, 200, NodeType::Function).emit_error()?;\n    tracing::info!(\"search_similar Success! with result {:?}\", ty_embed_data);\n\n    // Directly send snippets to RAG\n    let snippets = state\n        .io_handle\n        .get_snippets_batch(ty_embed_data.v)\n        .await\n        .unwrap_or_default()\n        .into_iter()\n        .filter_map(|r| r.ok())\n        .collect::<Vec<String>>();\n\n    // Send snippets directly to context manager\n    context_tx\n        .send(RagEvent::ContextSnippets(new_msg_id, snippets))\n        .await?;\n\n    // Then trigger context construction with the correct parent ID\n    let messages: Vec<Message> = state.chat.0.read().await.clone_current_path_conv();\n\n    context_tx\n        .send(RagEvent::UserMessages(new_msg_id, messages))\n        .await?;\n    context_tx\n        .send(RagEvent::ConstructContext(new_msg_id))\n        .await?;\n    Ok(())\n}"
      },
      {
        "name": "llm_manager",
        "dist": 1.281498908996582,
        "snippet": "pub async fn llm_manager(\n    mut event_rx: broadcast::Receiver<AppEvent>,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    // providers: crate::user_config::ProviderRegistry,\n) {\n    let client = Client::new();\n    let mut pending_requests = Vec::new();\n    let mut ready_contexts = std::collections::HashMap::new();\n\n    while let Ok(event) = event_rx.recv().await {\n        match event {\n            AppEvent::Llm(\n                request @ llm::Event::Request {\n                    parent_id,\n                    new_msg_id,\n                    ..\n                },\n            ) => {\n                tracing::info!(\n                    \"Received LLM request for parent_id: {}\n                new_msg_id: {}\n                \",\n                    parent_id,\n                    new_msg_id\n                );\n                pending_requests.push(request);\n            }\n            AppEvent::Llm(context @ llm::Event::PromptConstructed { parent_id, .. }) => {\n                tracing::info!(\"Received context for parent_id: {}\", parent_id);\n                ready_contexts.insert(parent_id, context);\n\n                let guard = state.config.read().await;\n                let maybe_provider = guard.provider_registry.get_active_provider();\n                if maybe_provider.is_none() {\n                    tracing::warn!(\"Could not find active provider in registry, returning early\");\n                    return;\n                }\n                let provider_config = maybe_provider\n                    .expect(\"Error in unwrapping a value guarenteed to be Some\")\n                    .clone();\n                drop(guard);\n                // Process any pending requests that now have context\n                pending_requests.retain(|req| {\n                    if let llm::Event::Request {\n                        new_msg_id: req_parent,\n                        // parent_id: req_parent,\n                        ..\n                    } = req\n                    {\n                        tracing::info!(\n                            \"pending_requests found match for req_parent: {}\",\n                            req_parent\n                        );\n                        if let Some(context) = ready_contexts.remove(req_parent) {\n                            tracing::info!(\n                                \"ready_contexts found match for req_parent: {}\",\n                                req_parent\n                            );\n                            tokio::spawn(process_llm_request(\n                                req.clone(),\n                                Arc::clone(&state),\n                                cmd_tx.clone(),\n                                client.clone(),\n                                provider_config.to_owned(),\n                                Some(context),\n                            ));\n                            tracing::info!(\"removing id from pending_requests\");\n                            false // Remove from pending\n                        } else {\n                            tracing::info!(\"keep id from pending_requests\n                                found pending_request but not ready_context\n                                checking if ready_contexts removed req_parent during conditional: {}\", \n                                ready_contexts.contains_key(req_parent));\n                            true // Keep waiting\n                        }\n                    } else {\n                        tracing::info!(\"keep id from pending_requests\nno matched pending_requests\");\n                        true\n                    }\n                });\n            }\n            _ => {}\n        }\n    }\n}"
      },
      {
        "name": "test_update_embed",
        "dist": 1.2920328378677368,
        "snippet": "#[tokio::test]\n    async fn test_update_embed() -> color_eyre::Result<()> {\n        init_test_tracing(Level::INFO);\n        let workspace_root = workspace_root();\n        let target_crate = \"fixture_update_embed\";\n        let workspace = \"tests/fixture_crates/fixture_update_embed\";\n\n        // ensure file begins in same state by using backup\n        let backup_file = PathBuf::from(format!(\"{}/{}/src/backup_main.bak\", workspace_root.display(), workspace));\n        tracing::info!(\"reading from backup files: {}\", backup_file.display());\n        let backup_contents = std::fs::read(&backup_file)?;\n        let target_main = backup_file.with_file_name(\"main.rs\");\n        std::fs::write(&target_main, backup_contents)?;\n\n        let cozo_db = if target_crate.starts_with(\"fixture\") { \n            setup_db_full(target_crate)\n        } else if target_crate.starts_with(\"crates\") {\n            let crate_name = target_crate.trim_start_matches(\"crates/\");\n            setup_db_full_crate(crate_name)\n        } else { \n            panic!(\"Incorrect usage of the test db setup\");\n        }?;\n\n        dotenvy::dotenv().ok();\n\n        let mut config = config::Config::builder()\n            .add_source(\n                config::File::with_name(\n                    &dirs::config_dir()\n                        .unwrap() // TODO: add error handling\n                        .join(\"ploke/config.toml\")\n                        .to_string_lossy(),\n                )\n                .required(false),\n            )\n            .add_source(config::Environment::default().separator(\"_\"))\n            .build()?\n            .try_deserialize::<crate::user_config::Config>()\n            .unwrap_or_else(|_| crate::user_config::Config::default());\n\n        // Merge curated defaults with user overrides\n        config.registry = config.registry.with_defaults();\n\n        // Apply API keys from environment variables to all providers\n        // config.registry.load_api_keys();\n        tracing::debug!(\"Registry after merge: {:#?}\", config.registry);\n        let new_db = ploke_db::Database::new(cozo_db);\n        let db_handle = Arc::new(new_db);\n\n        // Initial parse is now optional - user can run indexing on demand\n        // run_parse(Arc::clone(&db_handle), Some(TARGET_DIR_FIXTURE.into()))?;\n\n        // TODO: Change IoManagerHandle so it doesn't spawn its own thread, then use similar pattern to\n        // spawning state meager below.\n        let io_handle = ploke_io::IoManagerHandle::new();\n\n        // TODO: These numbers should be tested for performance under different circumstances.\n        let event_bus_caps = EventBusCaps {\n            realtime_cap: 100,\n            background_cap: 1000,\n            error_cap: 100,\n            index_cap: 1000,\n        };\n        let event_bus = Arc::new(EventBus::new(event_bus_caps));\n\n        let processor = config.load_embedding_processor()?;\n        let proc_arc = Arc::new(processor);\n\n        // TODO:\n        // 1 Implement the cancellation token propagation in IndexerTask\n        // 2 Add error handling for embedder initialization failures\n        let indexer_task = IndexerTask::new(\n            db_handle.clone(),\n            io_handle.clone(),\n            Arc::clone(&proc_arc), // Use configured processor\n            CancellationToken::new().0,\n            8,\n        );\n\n        let state = Arc::new(AppState {\n            chat: ChatState::new(ChatHistory::new()),\n            config: ConfigState::default(),\n            system: SystemState::default(),\n            indexing_state: RwLock::new(None), // Initialize as None\n            indexer_task: Some(Arc::new(indexer_task)),\n            indexing_control: Arc::new(Mutex::new(None)),\n            db: db_handle.clone(),\n            embedder: Arc::clone(&proc_arc),\n            io_handle: io_handle.clone(),\n        });\n        {\n            let mut system_guard = state.system.write().await;\n            let path = workspace_root.join(workspace);\n            system_guard.crate_focus = Some(path);\n            tracing::info!(\"system_guard.crate_focus: {:?}\", system_guard.crate_focus);\n        }\n\n        // Create command channel with backpressure\n        let (cmd_tx, cmd_rx) = mpsc::channel::<StateCommand>(1024);\n\n        let (rag_event_tx, rag_event_rx) = mpsc::channel(10);\n        let context_manager = ContextManager::new(rag_event_rx, Arc::clone(&event_bus));\n        tokio::spawn(context_manager.run());\n\n        let (cancellation_token, cancel_handle) = CancellationToken::new();\n        let (filemgr_tx, filemgr_rx) = mpsc::channel::<AppEvent>(256);\n        let file_manager = FileManager::new(\n            io_handle.clone(),\n            event_bus.subscribe(EventPriority::Background),\n            event_bus.background_tx.clone(),\n            rag_event_tx.clone(),\n            event_bus.realtime_tx.clone(),\n        );\n\n        tokio::spawn(file_manager.run());\n\n        // Spawn state manager first\n        tokio::spawn(state_manager(\n            state.clone(),\n            cmd_rx,\n            event_bus.clone(),\n            rag_event_tx,\n        ));\n\n        // Set global event bus for error handling\n        set_global_event_bus(event_bus.clone()).await;\n\n        // let script = r#\"?[name, id, embedding] := *function{name, id, embedding @ 'NOW' }\"#;\n        let script = r#\"?[name, time, is_assert, maybe_null, id] := *function{ id, at, name, embedding }\n                                or *struct{ id, at, name, embedding } \n                                or *module{ id, at, name, embedding } \n                                or *static{ id, at, name, embedding } \n                                or *const{ id, at, name, embedding }, \n                                  time = format_timestamp(at),\n                                  is_assert = to_bool(at),\n                                  maybe_null = !is_null(embedding)\n        \"#;\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n\n        // Spawn subsystems with backpressure-aware command sender\n        let command_style = config.command_style;\n        tokio::spawn(llm_manager(\n            event_bus.subscribe(EventPriority::Background),\n            state.clone(),\n            cmd_tx.clone(), // Clone for each subsystem\n        ));\n        tokio::spawn(run_event_bus(Arc::clone(&event_bus)));\n\n        // setup target file:\n\n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after indexing\n        // or *struct{name, id, embedding & 'NOW'}\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        fn iter_col<'a>(query_result: &'a QueryResult, col_title: &str) -> Option< impl Iterator<Item = &'a DataValue> > {\n            let col_idx = query_result.headers.iter().enumerate().find(|(idx, col)| col.as_str() == col_title)\n                .map(|(idx, col)| idx)?;\n            Some( query_result.rows.iter().map(move |r| r.index(col_idx)  ) )\n        }\n        fn is_id_embed_null(db_handle: &Database, ty: NodeType, id: AnyNodeId) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let cozo_id = id.to_cozo_uuid();\n            let one_script = format!(\n                \"?[name, item_id, is_embedding_null] := *{rel_name}{{ name, id: item_id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_id = {cozo_id}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        fn is_name_embed_null(db_handle: &Database, ty: NodeType, name: &str) -> Result< bool > {\n            let rel_name = ty.relation_str();\n            let one_script = format!(\n                \"?[item_name, id, is_embedding_null] := *{rel_name}{{ name: item_name, id, embedding @ 'NOW' }},\n                    is_embedding_null = is_null(embedding),\n                    item_name = {name:?}\"\n            );\n            let query = db_handle.raw_query(&one_script)?;\n            let is_embedding_null_now = iter_col(&query, \"is_embedding_null\").expect(\"column not found\")\n                .next().expect(\"row not found\")\n                .get_bool().expect(\"cell not expected datatype (bool)\");\n            Ok(is_embedding_null_now)\n        }\n        let one_script = r#\"\n            ?[name, id, is_embedding_null] := *const{ name, id, embedding @ 'NOW' },\n                is_embedding_null = is_null(embedding)\n        \"#;\n        let query_one = db_handle.raw_query(one_script)?;\n        let is_const_embedding_null_now = iter_col(&query_one, \"is_embedding_null\").expect(\"column not found\")\n            .next().expect(\"row not found\")\n            .get_bool().expect(\"cell not expected datatype (bool)\");\n        assert!(!is_const_embedding_null_now);\n\n        // items in as-yet unchanged file, expect to be embedded initially (before scan sets them to null\n        // again)\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        let mut target_file = PathBuf::new();\n        {\n            let mut system_guard = state.system.write().await;\n            system_guard.crate_focus = Some( workspace_root.join(workspace) );\n            target_file = system_guard.crate_focus.clone().expect(\"Crate focus not set\");\n        }\n        tracing::info!(\"target_file before pushes:\n{}\", target_file.display());\n        target_file.push(\"src\");\n        target_file.push(\"main.rs\");\n        tracing::info!(\"target_file after pushes:\n{}\", target_file.display());\n\n        // ----- start test function ------\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of scan_for_change: {:?}\", result);\n        // ----- end test start test ------\n\n\n        \n        tracing::info!(\"waiting for scan_rx\");\n\n        // ----- await on end of test function `scan_for_change` -----\n        match scan_rx.await {\n            Ok(_) => tracing::info!(\"scan_rx received for end of scan_for_change\"),\n            Err(_) => tracing::info!(\"error in scan_rx awaiting on end of scan_for_change\")\n        };\n\n        \n        // print database output after scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // Nothing should have changed after running scan on the target when the target has not\n        // changed.\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // Same here\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        // ----- make change to target file -----\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"pub struct TestStruct(pub i32)\") {\n                \"struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n\n        // ----- start second scan -----\n        let (scan_tx, scan_rx) = oneshot::channel();\n        let result = scan_for_change(&state.clone(), &event_bus.clone(), scan_tx).await;\n        tracing::info!(\"result of after second scan_for_change: {:?}\", result);\n        // ----- end second scan -----\n\n        // print database output after second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have null embeddings after scan\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n\n        // -- simulating sending response from app back to index --\n        // At the end of `scan_for_change`, an `AppEvent` is sent, which is processed inside the\n        // app event loop (not running here), which should print a message and then send another\n        // message to index the unembedded items in the database, which should currently only be\n        // the items detected as having changed through `scan_for_change`.\n        \n        cmd_tx.send(StateCommand::IndexWorkspace { workspace: workspace.to_string(), needs_parse: false }).await?;\n        let mut app_rx = event_bus.index_subscriber();\n        while let Ok(event) = app_rx.recv().await {\n            match event {\n                IndexingStatus { status: IndexStatus::Running, ..} => {\n                    tracing::info!(\"IndexStatus Running\");\n                },\n                IndexingStatus { status: IndexStatus::Completed, ..} => {\n                    tracing::info!(\"IndexStatus Completed, breaking loop\");\n                    break;\n                },\n                _ => {}\n            }\n        }\n\n        // print database output after reindex following the second scan\n        let query_result = db_handle.raw_query(script)?;\n        let printable_rows = query_result.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n        tracing::info!(\"rows from db:\n{printable_rows}\");\n\n        // items in changed file, expect to have embeddings again after scan\n        assert!(!is_name_embed_null(&db_handle, NodeType::Const, \"NUMBER_ONE\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Static, \"STR_TWO\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"TestStruct\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"double_inner_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Module, \"inner_test_mod\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"func_with_params\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"main\")?);\n        // items not in changed file, expect to be remain embedded\n        assert!(!is_name_embed_null(&db_handle, NodeType::Function, \"simple_four\")?);\n        assert!(!is_name_embed_null(&db_handle, NodeType::Struct, \"OtherStruct\")?);\n\n        tracing::info!(\"changing back:\n{}\", target_file.display());\n        let contents = std::fs::read_to_string(&target_file)?;\n        tracing::info!(\"reading file:\n{}\", &contents);\n        let changed = contents.lines().map(|l| {\n            if l.contains(\"struct TestStruct(pub i32)\") {\n                \"pub struct TestStruct(pub i32);\"\n            } else {\n                l\n            }\n        }).join(\"\n\");\n        tracing::info!(\"writing changed file:\n{}\", &changed);\n        std::fs::write(&target_file, changed)?;\n        Ok(())\n    }"
      },
      {
        "name": "add_msg_immediate",
        "dist": 1.3191381692886353,
        "snippet": "#[instrument(skip(state))]\nasync fn add_msg_immediate(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    new_msg_id: Uuid,\n    content: String,\n    kind: MessageKind,\n) {\n    tracing::trace!(\"Starting add_msg_immediate\");\n    let mut chat_guard = state.chat.0.write().await;\n    let parent_id = chat_guard.current;\n\n    let message_wrapper = match kind {\n        MessageKind::User => chat_guard.add_message_user(parent_id, new_msg_id, content.clone()),\n        MessageKind::System => todo!(),\n        MessageKind::Assistant => {\n            chat_guard.add_message_llm(parent_id, new_msg_id, kind, content.clone())\n        }\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => {\n            chat_guard.add_message_system(parent_id, new_msg_id, kind, content.clone())\n        }\n    };\n    drop(chat_guard);\n    // Add the user's message to the history\n    if let Ok(message_id) = message_wrapper {\n        let mut chat_guard = state.chat.0.write().await;\n        // Update the current message to the one we just added\n        chat_guard.current = message_id;\n        drop(chat_guard);\n\n        // Notify the UI that the state has changed\n        event_bus.send(MessageUpdatedEvent::new(message_id).into());\n\n        if kind == MessageKind::User {\n            // Trigger the LLM to generate a response to the user's message\n            let llm_request = AppEvent::Llm(llm::Event::Request {\n                request_id: Uuid::new_v4(),\n                parent_id: message_id,\n                new_msg_id,\n                prompt: content,\n                parameters: Default::default(), // Using mock/default param\n            });\n            tracing::info!(\n                \"sending llm_request wrapped in an AppEvent::Llm of kind {kind} with ids \n                new_msg_id (not sent): {new_msg_id},\n                parent_id: {parent_id}\n                message_id: {message_id},\",\n            );\n            event_bus.send(llm_request);\n        }\n    } else {\n        tracing::error!(\"Failed to add message of kind: {}\", kind);\n    }\n}"
      },
      {
        "name": "batch_prompt_search",
        "dist": 1.3298964500427246,
        "snippet": "/// Performs batch semantic search on prompts from a file and returns results\n///\n/// This function reads prompts from a file, generates embeddings for each prompt,\n/// performs semantic search against the database, and returns the results in a\n/// structured format suitable for serialization.\n///\n/// # Arguments\n///\n/// * `state` - Shared application state containing database and embedder\n/// * `prompt_file` - Path to file containing prompts (separated by \"---\")\n/// * `out_file` - Path to output file for results (JSON format)\n/// * `max_hits` - Maximum number of similar snippets to return per prompt\n/// * `threshold` - Optional similarity threshold for filtering results\n///\n/// # Returns\n///\n/// Returns a vector of batch results containing prompt indices, original prompts,\n/// and their corresponding code snippets found through semantic search.\n/// Results are automatically written to the specified output file as JSON.\npub(super) async fn batch_prompt_search(\n    state: &Arc< AppState >,\n    prompt_file: String,\n    out_file: String,\n    max_hits: Option<usize>,\n    threshold: Option<f32>,\n) -> color_eyre::Result<Vec<BatchResult>> {\n    use std::fs;\n    use ploke_embed::indexer::EmbeddingProcessor;\n    \n    let raw_prompts = fs::read_to_string(&prompt_file)?;\n    let prompt_json = serde_json::from_str(&raw_prompts)?;\n    let prompt_data: Vec< PromptData > = serde_json::from_value(prompt_json)?;\n\n    \n    // I'd rather split by double newlines or something.\n    // let prompts: Vec<String> = prompts\n    //     .split(\"---\")\n    //     .map(|s| s.trim())\n    //     .filter(|s| !s.is_empty())\n    //     .map(|s| s.to_string())\n    //     .collect();\n    \n    if prompt_data.is_empty() {\n        return Ok(Vec::new());\n    }\n    \n    // let max_hits: usize = max_hits.unwrap_or(10);\n    let _threshold = threshold.unwrap_or(0.0);\n    \n    let mut results = Vec::new();\n    \n    for (prompt_idx, prompt_item) in prompt_data.iter().enumerate() {\n        let PromptData {prompt, k, ef, max_hits, radius} = prompt_item;\n        tracing::info!(\"Processing prompt {}: {}\", prompt_idx, prompt);\n        \n        let embeddings = state.embedder\n            .generate_embeddings(vec![prompt.clone()])\n            .await?;\n\n        \n        if let Some(embedding) = embeddings.into_iter().next() {\n            let k_range = 1..=101;\n\n            for k_val in k_range.step_by(5) {\n                let args = SimilarArgs {\n                    db: &state.db,\n                    vector_query: &embedding,\n                    k: k_val,\n                    ef: *ef,\n                    ty: NodeType::Function,\n                    max_hits: *max_hits,\n                    radius: *radius\n                };\n                let EmbedDataVerbose {typed_data, dist}= search_similar_args(args)?;\n                // let first_five = typed_data.v.into_iter().take(5).collect_vec();\n                let snippets = typed_data.v.iter().map(|i| i.name.clone()).collect_vec();\n\n                let code_snippets = state.io_handle\n                    .get_snippets_batch(typed_data.v).await?;\n                    // .get_snippets_batch(first_five).await?;\n                let mut ok_snippets: Vec<SnippetInfo> = Vec::new();\n                for ( ( snippet_result, name ), dist ) in code_snippets.into_iter().zip(snippets).zip(dist) {\n                    let unformatted = snippet_result?;\n                    let snippet = unformatted.split(\"\\\n\").join(\"\n\");\n                    let snippet_info = SnippetInfo {\n                        name,\n                        dist,\n                        snippet\n                    };\n                    ok_snippets.push(snippet_info);\n                }\n\n                results.push(BatchResult {\n                    prompt_idx,\n                    prompt: prompt.clone(),\n                    snippet_info: ok_snippets,\n                });\n            }\n        }\n    }\n    \n    // Write results to file\n    let json_content = serde_json::to_string_pretty(&results)?;\n    \n    fs::write(&out_file, json_content)?;\n    \n    Ok(results)\n}"
      },
      {
        "name": "run_event_bus",
        "dist": 1.3574821949005127,
        "snippet": "async fn run_event_bus(event_bus: Arc<EventBus>) -> Result<()> {\n    use broadcast::error::RecvError;\n    let mut index_rx = event_bus.index_subscriber();\n    #[allow(unused_mut)]\n    let mut bg_rx = event_bus.background_tx.subscribe();\n    // more here?\n    loop {\n        tokio::select! {\n        // bg_event = bg_rx.recv() => {\n        // tracing::trace!(\"event bus received a background event: {:?}\", bg_event);\n        //     match bg_event {\n        //         Ok(AppEvent::System(sys_event)) => match sys_event {\n        //             SystemEvent::ModelSwitched(alias_or_id) => {\n        //                 tracing::info!(\"event bus Sent RAG event with snippets: {:#?}\", alias_or_id);\n        //                 event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(alias_or_id)));\n        //             }\n        //             SystemEvent::SaveRequested(vec_bytes) => {\n        //                 tracing::info!(\"event bus Sent save event of Vec<u8> len = {}\", vec_bytes.len());\n        //                 event_bus.send(AppEvent::System(SystemEvent::SaveRequested(vec_bytes)));\n        //         }\n        //             _ => {}\n        //         },\n        //         Ok(_) => {}\n        //         Err(e) => {\n        //             match e {\n        //                 RecvError::Closed => {\n        //                     tracing::trace!(\"System Event event channel closed {}\", e.to_string());\n        //                     break;\n        //                 }\n        //                 RecvError::Lagged(lag) => {\n        //                     tracing::trace!(\n        //                         \"System Event event channel lagging {} with {} messages\",\n        //                         e.to_string(),\n        //                         lag,\n        //                     )\n        //                 }\n        //             };\n        //         }\n        //     }\n        // }\n            index_event = index_rx.recv() => {\n            // let index_event = index_rx.recv().await;\n            tracing::trace!(\"event bus received IndexStatus\");\n            match index_event {\n                Ok(status) => {\n                    match status.status {\n                        IndexStatus::Running => {\n                            tracing::warn!(\"event bus sending {:?}\", status.status);\n                            let result = event_bus\n                                .realtime_tx\n                                .send(AppEvent::IndexingProgress(status));\n                            tracing::warn!(\"with result {:?}\", result);\n                            continue;\n                        }\n                        IndexStatus::Completed => {\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingCompleted);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        IndexStatus::Cancelled => {\n                            // WARN: Consider whether this should count as a failure or not\n                            // when doing better error handling later.\n                            let result = event_bus.realtime_tx.send(AppEvent::IndexingFailed);\n                            tracing::warn!(\n                                \"event bus sending {:?} with result {:?}\",\n                                status.status,\n                                result\n                            );\n                            continue;\n                        }\n                        _ => {}\n                    }\n                }\n                Err(e) => match e {\n                    RecvError::Closed => {\n                        tracing::trace!(\"indexing task event channel closed {}\", e.to_string());\n                        // break;\n                    }\n                    RecvError::Lagged(lag) => {\n                        tracing::trace!(\n                            \"indexing task event channel lagging {} with {} messages\",\n                            e.to_string(),\n                            lag\n                        )\n                    }\n                },\n            }\n            }\n            // };\n        };\n    }\n    // Ok(())\n}"
      },
      {
        "name": "process_llm_request",
        "dist": 1.3595027923583984,
        "snippet": "#[instrument(skip(state, client, provider_config))]\npub async fn process_llm_request(\n    request: llm::Event,\n    state: Arc<AppState>,\n    cmd_tx: mpsc::Sender<StateCommand>,\n    client: Client,\n    provider_config: crate::user_config::ProviderConfig,\n    context: Option<llm::Event>,\n) {\n    tracing::info!(\"Inside process_llm_request\");\n    let parent_id = match request {\n        llm::Event::Request {\n            parent_id,\n            new_msg_id,\n            ..\n        } => new_msg_id,\n        _ => {\n            tracing::info!(\"Not a Request, do nothing\");\n            return;\n        } // Not a request, do nothing\n    };\n    tracing::info!(\"Inside process_llm_request\");\n\n    // This part remains the same: create a placeholder message first.\n    let (responder_tx, responder_rx) = oneshot::channel();\n    let create_cmd = StateCommand::CreateAssistantMessage {\n        parent_id,\n        responder: responder_tx,\n    };\n\n    if cmd_tx.send(create_cmd).await.is_err() {\n        log::error!(\"Failed to send CreateAssistantMessage command: channel closed.\");\n        return;\n    }\n\n    let assistant_message_id = match responder_rx.await {\n        Ok(id) => id,\n        Err(_) => {\n            log::error!(\"Failed to create assistant message: state_manager dropped responder.\");\n            return;\n        }\n    };\n\n    // Prepare and execute the API call, then create the final update command.\n    let update_cmd = prepare_and_run_llm_call(&state, &client, &provider_config, context)\n        .await\n        .map(|content| StateCommand::UpdateMessage {\n            id: assistant_message_id,\n            update: MessageUpdate {\n                content: Some(content),\n                status: Some(MessageStatus::Completed),\n                ..Default::default()\n            },\n        })\n        .unwrap_or_else(|e| {\n            let err_string = e.to_string();\n            StateCommand::UpdateMessage {\n                id: assistant_message_id,\n                update: MessageUpdate {\n                    content: Some(format!(\"Error: {}\", err_string)),\n                    status: Some(MessageStatus::Error {\n                        description: err_string,\n                    }),\n                    ..Default::default()\n                },\n            }\n        });\n\n    // Send the final update command to the state manager.\n    if cmd_tx.send(update_cmd).await.is_err() {\n        log::error!(\"Failed to send final UpdateMessage: channel closed.\");\n    }\n}"
      },
      {
        "name": "prepare_and_run_llm_call",
        "dist": 1.39385986328125,
        "snippet": "#[instrument(skip(provider, state, client))]\nasync fn prepare_and_run_llm_call(\n    state: &Arc<AppState>,\n    client: &Client,\n    provider: &ProviderConfig,\n    context: Option<llm::Event>,\n) -> Result<String, LlmError> {\n    // Get the conversation history from AppState\n    let history_guard = state.chat.0.read().await;\n    let path = history_guard.get_current_path();\n\n    let context_path = if path.len() > 1 {\n        &path[..path.len() - 1]\n    } else {\n        &path[..]\n    };\n    tracing::info!(\"Inside prepare_and_run_llm_call\");\n\n    let mut messages: Vec<RequestMessage> = Vec::new();\n\n    // Get parameters from provider\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n\n    // Prepend system prompt if provided\n    if let Some(sys) = params.system_prompt.as_ref() {\n        messages.push(RequestMessage::new_system(sys.clone()));\n    }\n\n    // Append the rest of the conversation\n    let conversation_messages = if let Some(Event::PromptConstructed { prompt, .. }) = context {\n        prompt\n            .into_iter()\n            .map(|(k, c)| RequestMessage {\n                role: k.into(),\n                content: c,\n            })\n            .collect::<Vec<_>>()\n    } else {\n        context_path\n            .iter()\n            .filter(|msg| (msg.kind != MessageKind::SysInfo) && !msg.content.is_empty())\n            .map(|msg| RequestMessage {\n                role: msg.kind.into(),\n                content: msg.content.clone(),\n            })\n            .collect::<Vec<_>>()\n    };\n\n    messages.extend(conversation_messages);\n\n    log::info!(\n        \"Sending conversation history message with content: {:#?}\",\n        messages\n    );\n    log::info!(\"Sending request using model config: {:#?}\", provider);\n    // Release the lock before the network call\n    drop(history_guard);\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num2 {:#?}\",\n        provider.llm_params\n    );\n    let params = provider.llm_params.as_ref().cloned().unwrap_or_default();\n    let request_payload = OpenAiRequest {\n        model: provider.model.as_str(),\n        messages,\n        temperature: params.temperature,\n        max_tokens: params.max_tokens,\n        top_p: params.top_p,\n        stream: false,\n    };\n\n    tracing::info!(\n        \"Inside prepare_and_run_llm_call num3 {:#?}\",\n        request_payload\n    );\n\n    let response_test = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload);\n    \n    tracing::info!(\n        \"request_payload is {:#?}\",\n        request_payload\n    );\n\n    let response = client\n        .post(format!(\"{}/chat/completions\", provider.base_url))\n        .bearer_auth(provider.resolve_api_key())\n        .json(&request_payload)\n        .send()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n\n    if !response.status().is_success() {\n        let status = response.status().as_u16();\n        let error_text = response\n            .text()\n            .await\n            .unwrap_or_else(|_| \"Could not retrieve error body\".to_string());\n\n        let user_friendly_msg = if status == 401 {\n            format!(\n                \"Authentication failed. Please check your API key configuration.\n\nDetails {}\",\n                error_text\n            )\n        } else if status == 429 {\n            format!(\n                \"Rate limit exceeded. Please wait and try again.\n\nDetails: {}\",\n                error_text\n            )\n        } else if status >= 500 {\n            format!(\n                \"Server error. The API provider may be experiencing issues.\n\nDetails: {}\",\n                error_text\n            )\n        } else {\n            format!(\"API error (status {}): {}\", status, error_text)\n        };\n\n        return Err(LlmError::Api {\n            status,\n            message: user_friendly_msg,\n        });\n    }\n\n    let body = response\n        .text()\n        .await\n        .map_err(|e| LlmError::Request(e.to_string()))?;\n    tracing::debug!(\"raw body: {}\", body);\n\n    // OpenRouter sometimes puts errors inside a 200 body\n    if let Ok(err) = serde_json::from_str::<serde_json::Value>(&body) {\n        if let Some(err_obj) = err.get(\"error\") {\n            let msg = err_obj\n                .get(\"message\")\n                .and_then(|v| v.as_str())\n                .unwrap_or(\"Unknown OpenRouter error\");\n            let code = err_obj.get(\"code\").and_then(|v| v.as_u64()).unwrap_or(0);\n            return Err(LlmError::Api {\n                status: code as u16,\n                message: msg.to_string(),\n            });\n        }\n    }\n\n    // Now safe to deserialize into OpenAiResponse\n    let response_body: OpenAiResponse = serde_json::from_str(&body)\n        .map_err(|e| LlmError::Deserialization(format!(\"{}  body was: {}\", e, body)))?;\n    tracing::trace!(\"raw body response to request: {:#?}\", body);\n\n    let content = response_body\n        .choices\n        .into_iter()\n        .next()\n        .map(|c| c.message.content)\n        .unwrap_or_else(|| \"No content received from API.\".to_string());\n\n    Ok(content)\n}"
      },
      {
        "name": "load_db",
        "dist": 1.3975799083709717,
        "snippet": "/// Loads a previously saved database backup into the application.\n///\n/// This function searches the default configuration directory for a database backup file\n/// created by the `SaveDb` command. The backup file follows a naming convention where it\n/// begins with the human-readable crate name, followed by an underscore and a v5 UUID hash\n/// obtained from `state.db.get_crate_name_id`.\n///\n/// # Process\n/// 1. Locates the backup file in the default configuration directory\n/// 2. Imports the backup into the current database using CozoDB's restore functionality\n/// 3. Validates the restored database has content\n/// 4. Updates application state to reflect the loaded crate\n/// 5. Emits appropriate success/failure events\n///\n/// # Arguments\n/// * `state` - Reference to the application state containing the database\n/// * `event_bus` - Event bus for sending status updates\n/// * `crate_name` - Name of the crate to load from backup\n///\n/// # Returns\n/// Returns `Ok(())` if the database was successfully loaded, or an appropriate error\n/// if the backup file was not found or the restore operation failed.\n///\n/// # Notes\n/// The CozoDB restore operation must be performed on an empty database. If the current\n/// database contains data, it will be replaced by the backup. The function handles\n/// the full lifecycle of locating, validating, and restoring the database state.\npub(super) async fn load_db(\n    state: &Arc<AppState>,\n    event_bus: &Arc<EventBus>,\n    crate_name: String,\n) -> Result<(), ploke_error::Error> {\n    let mut default_dir = dirs::config_local_dir().ok_or_else(|| {\n        let err_msg = \"Could not locate default config directory on system\";\n        let e =\n            ploke_error::Error::Fatal(ploke_error::FatalError::DefaultConfigDir { msg: err_msg });\n        e.emit_warning();\n        event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n            crate_name: crate_name.clone(),\n            file_dir: None,\n            is_success: false,\n            error: Some(err_msg),\n        }));\n        e\n    })?;\n    default_dir.push(\"ploke/data\");\n    let valid_file = match find_file_by_prefix(default_dir.as_path(), &crate_name).await {\n        Ok(Some(path_buf)) => Ok(path_buf),\n        Ok(None) => {\n            let err_msg = \"No backup file detected at default configuration location\";\n            let error = ploke_error::WarningError::PlokeDb(err_msg.to_string());\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(error)\n        }\n        Err(e) => {\n            // TODO: Improve this error message\n            tracing::error!(\"Failed to load file: {}\", e);\n            let err_msg = \"Could not find saved file, io error\";\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name: crate_name.clone(),\n                file_dir: Some(Arc::new(default_dir)),\n                is_success: false,\n                error: Some(err_msg),\n            }));\n            Err(ploke_error::FatalError::DefaultConfigDir { msg: err_msg })?\n        }\n    }?;\n\n    let prior_rels_vec = state.db.relations_vec()?;\n    tracing::debug!(\"prior rels for import: {:#?}\", prior_rels_vec);\n    state\n        .db\n        .import_from_backup(&valid_file, &prior_rels_vec)\n        .map_err(ploke_db::DbError::from)\n        .map_err(ploke_error::Error::from)?;\n    // .inspect_err(|e| e.emit_error())?;\n\n    // get count for sanity and user feedback\n    match state.db.count_relations().await {\n        Ok(count) if count > 0 => {\n            {\n                let mut system_guard = state.system.write().await;\n                let script = format!( \n                    \"?[root_path] := *crate_context {{name: crate_name, root_path @ 'NOW' }}, crate_name = \\\"{crate_name}\\\"\"\n                );\n                let db_res = state.db.raw_query(&script)?;\n                let crate_root_path = db_res.rows.first().and_then(|c| c.first())\n                    .ok_or_else(|| {\n                        let msg = \"Incorrect retrieval of crate context, no first row/column\";\n                        tracing::error!(msg);\n                        ploke_error::Error::Warning(ploke_error::WarningError::PlokeDb(msg.to_string()))\n                    }).map(|v| v.get_str().expect(\"Crate must always be a string\"))?;\n                let target_dir = std::env::current_dir().inspect_err(|e| tracing::error!(\"Error finding current dir: {e}\")).ok();\n                \n                system_guard.crate_focus = target_dir.map(|cd| cd.join(crate_root_path));\n            }\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: true,\n                error: None,\n            }));\n            Ok(())\n        }\n        Ok(count) => {\n            event_bus.send(AppEvent::System(SystemEvent::LoadDb {\n                crate_name,\n                file_dir: Some(Arc::new(valid_file)),\n                is_success: false,\n                error: Some(\"Database backed up from file, but 0 relations found.\"),\n            }));\n            Ok(())\n        }\n        Err(e) => Err(e),\n    }\n}"
      },
      {
        "name": "resolve_target_dir",
        "dist": 1.401613473892212,
        "snippet": "/// Returns the directory to process.\n/// Priority:\n/// 1. Path supplied by the caller\n/// 2. `$PWD` (current working directory)\n///\n/// # Examples\n///\n/// ```\n/// use std::path::PathBuf;\n/// use std::env;\n///\n/// // When user provides a path, it should be returned\n/// let user_path = PathBuf::from(\"/some/path\");\n/// let result = ploke_tui::parser::resolve_target_dir(Some(user_path.clone()));\n/// assert_eq!(result.unwrap(), user_path);\n///\n/// // When no path is provided, it should return current directory\n/// let current_dir = env::current_dir().unwrap();\n/// let result = ploke_tui::parser::resolve_target_dir(None);\n/// assert_eq!(result.unwrap(), current_dir);\n/// ```\npub fn resolve_target_dir(user_dir: Option<PathBuf>) -> Result<PathBuf, ploke_error::Error> {\n    let target_dir = match user_dir {\n        Some(p) => p,\n        None => env::current_dir().map_err(SynParserError::from)?,\n    };\n    Ok(target_dir)\n}"
      },
      {
        "name": "state_manager",
        "dist": 1.4092812538146973,
        "snippet": "pub async fn state_manager(\n    state: Arc<AppState>,\n    mut cmd_rx: mpsc::Receiver<StateCommand>,\n    event_bus: Arc<EventBus>,\n    context_tx: mpsc::Sender<RagEvent>,\n) {\n    while let Some(cmd) = cmd_rx.recv().await {\n        // Update the span with the command discriminant\n        let span = tracing::debug_span!(\n            \"processing\",\n            cmd = %cmd.discriminant(),\n        );\n        let _enter = span.enter();\n\n        match cmd {\n            StateCommand::UpdateMessage { id, update } => {\n                tracing::Span::current().record(\"msg_id\", format!(\"{}\", id));\n                tracing::debug!(\n                    content = ?update.content.as_ref().map(|c| truncate_string(c, 20)),\n                    \"Updating message\"\n                );\n                let mut chat_guard = state.chat.0.write().await;\n\n                if let Some(message) = chat_guard.messages.get_mut(&id) {\n                    match message.try_update(update) {\n                        Ok(_) => {\n                            // Notify UI of update\n                            event_bus.send(MessageUpdatedEvent::new(id).into());\n                        }\n                        Err(e) => {\n                            event_bus.send(UpdateFailedEvent::new(id, e).into());\n                        }\n                    }\n                }\n            }\n            StateCommand::AddUserMessage {\n                content,\n                new_msg_id,\n                completion_tx,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, content, MessageKind::User).await;\n                completion_tx\n                    .send(())\n                    .expect(\"AddUserMessage should never fail to send tx\");\n            }\n            StateCommand::AddMessage {\n                parent_id,\n                child_id,\n                content,\n                // TODO: Figure out if I should/need to do more with these\n                kind,\n                target,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                // For assistant messages, lthe status will be Generating initially\n                let status = if matches!(kind, MessageKind::Assistant) {\n                    MessageStatus::Generating\n                } else {\n                    MessageStatus::Completed\n                };\n\n                if let Ok(new_message_id) =\n                    chat_guard.add_child(parent_id, child_id, &content, status, kind)\n                {\n                    chat_guard.current = new_message_id;\n                    event_bus.send(MessageUpdatedEvent::new(new_message_id).into())\n                }\n            }\n            StateCommand::AddMessageImmediate {\n                msg,\n                kind,\n                new_msg_id,\n            } => {\n                add_msg_immediate(&state, &event_bus, new_msg_id, msg, kind).await;\n            }\n            StateCommand::PruneHistory { max_messages } => {\n                // TODO: This will provide a way to prune the alternate branches of the\n                // conversation tree, once the conversation tree has been implemented.\n                todo!(\"Handle PruneHistory\")\n            }\n\n            StateCommand::NavigateList { direction } => {\n                let mut chat_guard = state.chat.0.write().await;\n                chat_guard.navigate_list(direction);\n                event_bus.send(MessageUpdatedEvent(chat_guard.current).into())\n            }\n\n            StateCommand::CreateAssistantMessage {\n                parent_id,\n                responder,\n            } => {\n                let mut chat_guard = state.chat.0.write().await;\n                let child_id = Uuid::new_v4();\n                let status = MessageStatus::Generating;\n                let kind = crate::chat_history::MessageKind::Assistant;\n\n                if let Ok(new_id) =\n                    chat_guard.add_child(parent_id, child_id, \"Pending...\", status, kind)\n                {\n                    // update the state of the current id to the newly generated pending message.\n                    chat_guard.current = new_id;\n\n                    // Send the ID back to the requester.\n                    // Ignore error in case the requester timed out and dropped the receiver.\n                    let _ = responder.send(new_id);\n\n                    // Notify the UI to render the new placeholder message.\n                    event_bus.send(MessageUpdatedEvent::new(new_id).into());\n                }\n                // TODO: Consider if this is proper error handling or not.\n                // If add_child fails, the responder is dropped, signaling an error to the awaiter.\n            }\n            StateCommand::IndexWorkspace {\n                workspace,\n                needs_parse,\n            } => {\n                let (control_tx, control_rx) = tokio::sync::mpsc::channel(4);\n                let target_dir = {\n                    let mut write_guard = state.system.write().await;\n                    let crate_focus = match std::env::current_dir() {\n                        Ok(current_dir) => {\n                            let mut pwd = current_dir;\n                            pwd.push(&workspace);\n                            pwd\n                        }\n                        Err(e) => {\n                            tracing::error!(\"Error resolving current dir: {e}\");\n                            continue;\n                        }\n                    };\n                    tracing::debug!(\"Setting crate_focus to {}\", crate_focus.display());\n                    write_guard.crate_focus = Some(crate_focus.clone());\n                    crate_focus\n                };\n\n                // TODO: maybe run_parse should be returning the name of the crate it parsed, as\n                // defined in the `Cargo.toml`? For now we are just going to use the directory name\n                // as the name of the crate.\n                if needs_parse {\n                    match run_parse(Arc::clone(&state.db), Some(target_dir.clone())) {\n                        Ok(_) => tracing::info!(\n                            \"Parse of target workspace {} successful\",\n                            &target_dir.display()\n                        ),\n                        Err(e) => {\n                            tracing::info!(\n                                \"Failure parsing directory from IndexWorkspace event: {}\",\n                                e\n                            );\n                            return;\n                        }\n                    }\n                }\n                // let mut chat_guard = state.chat.0.write().await;\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    Uuid::new_v4(), // double check this is OK\n                    \"Indexing...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                let event_bus_clone = event_bus.clone();\n                // let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_tx = Arc::clone(&event_bus.index_tx);\n                let progress_rx = event_bus.index_subscriber();\n\n                let state_arc = state.indexer_task.as_ref().map(Arc::clone);\n                if let Some(indexer_task) = state_arc {\n                    if let Ok((callback_manager, db_callbacks, unreg_codes_arc, shutdown)) =\n                        ploke_db::CallbackManager::new_bounded(Arc::clone(&indexer_task.db), 1000)\n                    {\n                        let counter = callback_manager.clone_counter();\n                        let callback_handler = std::thread::spawn(move || callback_manager.run());\n                        let res = tokio::spawn(async move {\n                            let indexing_result = IndexerTask::index_workspace(\n                                indexer_task,\n                                workspace,\n                                progress_tx,\n                                progress_rx,\n                                control_rx,\n                                callback_handler,\n                                db_callbacks,\n                                counter,\n                                shutdown,\n                            )\n                            .await;\n                            tracing::info!(\"Indexer task returned\");\n                            match indexing_result {\n                                Ok(_) => {\n                                    tracing::info!(\"Sending Indexing Completed\");\n                                    event_bus_clone.send(AppEvent::IndexingCompleted)\n                                }\n                                Err(e) => {\n                                    tracing::warn!(\n                                        \"Sending Indexing Failed with error message: {}\",\n                                        e.to_string()\n                                    );\n                                    event_bus_clone.send(AppEvent::IndexingFailed)\n                                }\n                            }\n                        })\n                        .await;\n                        match res {\n                            Ok(_) => {\n                                tracing::info!(\"Sending Indexing Completed\");\n                            }\n                            Err(e) => {\n                                tracing::warn!(\n                                    \"Sending Indexing Failed with error message: {}\",\n                                    e.to_string()\n                                );\n                            }\n                        }\n                        tracing::info!(\"Indexer task returned\");\n                    }\n                }\n            }\n            StateCommand::PauseIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Pause).await.ok();\n                }\n            }\n\n            StateCommand::ResumeIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Resume).await.ok();\n                }\n            }\n\n            StateCommand::CancelIndexing => {\n                if let Some(ctrl) = &mut *state.indexing_control.lock().await {\n                    ctrl.send(IndexerCommand::Cancel).await.ok();\n                }\n            }\n            StateCommand::SaveState => {\n                let serialized_content = {\n                    let guard = state.chat.0.read().await;\n                    guard.format_for_persistence().as_bytes().to_vec()\n                };\n                event_bus.send(AppEvent::System(SystemEvent::SaveRequested(\n                    serialized_content,\n                )))\n            }\n            StateCommand::UpdateDatabase => {\n                let start = time::Instant::now();\n                let new_msg_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    new_msg_id,\n                    \"Indexing HNSW...\".to_string(),\n                    MessageKind::SysInfo,\n                )\n                .await;\n                // TODO: Decide if this needs to be replaced.\n                for ty in NodeType::primary_nodes() {\n                    match create_index_warn(&state.db, ty) {\n                        Ok(_) => {\n                            tracing::info!(\n                                \"Database index updated by create_index_warn for rel: {}\",\n                                ty.relation_str()\n                            );\n                        }\n                        Err(e) => {\n                            match replace_index_warn(&state.db, ty) {\n                                Ok(_) => {\n                                    tracing::info!(\n                                        \"Database index updated by replace_index_warn for rel: {}\",\n                                        ty.relation_str()\n                                    );\n                                }\n                                Err(e) => tracing::warn!(\n                                    \"The attempt to replace the index at the database failed\"\n                                ),\n                            }\n                            tracing::warn!(\"The attempt to create the index at the database failed\")\n                        }\n                    }\n                }\n                let after = time::Instant::now();\n                let msg = format!(\"..finished in {}\", after.duration_since(start).as_millis());\n                let second_new_message_id = Uuid::new_v4();\n                add_msg_immediate(\n                    &state,\n                    &event_bus,\n                    second_new_message_id,\n                    msg,\n                    MessageKind::SysInfo,\n                )\n                .await;\n            }\n            StateCommand::EmbedMessage {\n                new_msg_id,\n                completion_rx,\n                scan_rx,\n            } => {\n                if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, completion_rx).await {\n                    continue;\n                }\n                let chat_guard = state.chat.0.read().await;\n                match chat_guard.last_user_msg() {\n                    Ok(Some((last_usr_msg_id, last_user_msg))) => {\n                        tracing::info!(\"Start embedding user message: {}\", last_user_msg);\n                        let temp_embed = state\n                            .embedder\n                            .generate_embeddings(vec![last_user_msg])\n                            .await\n                            .expect(\"Error while generating embedding of user message\");\n                        // drop guard after we are done with last_usr_message, which is consumed by\n                        // generate_embeddings\n                        drop(chat_guard);\n                        let embeddings = temp_embed\n                            .into_iter()\n                            .next()\n                            .expect(\"No results from user message embedding generation\");\n                        tracing::info!(\"Finish embedding user message\");\n\n                        tracing::info!(\"Waiting to finish processing updates to files, if any\");\n                        // Wait on the oneshot from `scan_for_change`, letting us know that the database\n                        // has been updated with the embeddings from any recent changes, if there were any.\n                        if let ControlFlow::Break(_) = wait_on_oneshot(new_msg_id, scan_rx).await {\n                            continue;\n                        }\n                        tracing::info!(\"Finished waiting on parsing target crate\");\n\n                        if let Err(e) =\n                            embedding_search_similar(&state, &context_tx, new_msg_id, embeddings)\n                                .await\n                        {\n                            tracing::error!(\"error during embedding search: {}\", e);\n                        };\n                    }\n                    Ok(None) => {\n                        tracing::warn!(\n                            \"Could not retreive last user message from the conversation history\"\n                        );\n                    }\n                    Err(e) => {\n                        tracing::error!(\"Error accessing last user message: {:#}\", e);\n                    }\n                }\n            }\n\n            StateCommand::SwitchModel { alias_or_id } => {\n                models::switch_model(&state, &event_bus, alias_or_id).await;\n            }\n\n            StateCommand::LoadQuery {\n                query_name,\n                query_content,\n            } => {\n                database::load_query(&state, query_content).await;\n            }\n            StateCommand::ReadQuery {\n                query_name,\n                file_name,\n            } => {\n                let _ = event_bus\n                    .realtime_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name: query_name.clone(),\n                        file_name: file_name.clone(),\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n                let _ = event_bus\n                    .background_tx\n                    .send(AppEvent::System(SystemEvent::ReadQuery {\n                        query_name,\n                        file_name,\n                    }))\n                    .inspect_err(|e| tracing::warn!(\"Error forwarding event: {e:?}\"));\n            }\n            StateCommand::SaveDb => {\n                use database::save_db;\n                // TODO: Refactor `save_db` to return a message that is sent through the\n                // `event_bus` here so we don't use too much indirection when sending messages\n                // through the event system.\n                if let ControlFlow::Break(_) = save_db(&state, &event_bus).await {\n                    continue;\n                }\n            }\n            StateCommand::BatchPromptSearch {\n                prompt_file,\n                out_file,\n                max_hits,\n                threshold,\n            } => {\n                match batch_prompt_search(&state, prompt_file, out_file, max_hits, threshold).await {\n                    Ok(embed_data) => {\n                        tracing::info!(\"Batch prompt search succeeded with {} results.\", embed_data.len());\n                    },\n                    Err(e) =>{\n                        // Log the full error with context using tracing's error macro\n                        // color_eyre::Report provides rich context including backtrace\n                        tracing::error!(\n                            error = %e,\n                            error_chain = ?e.chain().collect::<Vec<_>>(),\n                            \"Batch prompt search failed\"\n                        );\n\n                        // TODO: Once I'm sure the rest of this works I'll add this, but for now I\n                        // don't want to make too many changes, especially to the event and messaging\n                        // loop, before testing.\n                        // Also emit as a warning event to the UI\n                        // event_bus.send(AppEvent::System(SystemEvent::Error(\n                        //     format!(\"Batch prompt search failed: {}\", e)\n                        // )));\n                    }\n                }\n            }\n            StateCommand::LoadDb { crate_name } => {\n                // TODO: Refactor this to be a function, and change the `continue` to handling the\n                // result with `?`\n                if let Err(e) = database::load_db(&state, &event_bus, crate_name).await {\n                    match e {\n                        ploke_error::Error::Fatal(_) => e.emit_fatal(),\n                        ploke_error::Error::Warning(_) | ploke_error::Error::Internal(_) => {\n                            e.emit_warning()\n                        }\n                        _ => {\n                            todo!(\"These should never happen.\")\n                        }\n                    }\n                }\n                // TODO: run hnsw indexer again here using cozo command.\n            }\n\n            StateCommand::ScanForChange { scan_tx } => {\n                let _ = database::scan_for_change(&state, &event_bus, scan_tx)\n                    .await\n                    .inspect_err(|e| {\n                        e.emit_error();\n                        tracing::error!(\"Error in ScanForChange:\n{e}\");\n                    });\n            }\n\n            // ... other commands\n            // TODO: Fill out other fields\n            _ => {}\n        };\n    }\n}"
      },
      {
        "name": "load_query",
        "dist": 1.4213216304779053,
        "snippet": "pub(super) async fn load_query(state: &Arc<AppState>, query_content: String) {\n    let result = state.db.raw_query_mut(&query_content)\n        .inspect_err(|e| tracing::error!(\"{e}\"));\n    tracing::info!(target: \"load_query\", \"testing query result\n{:#?}\", result);\n    if let Ok(named_rows) = result {\n        let mut output = String::new();\n        let (header, rows) = (named_rows.headers, named_rows.rows);\n        let cols_num = header.len();\n        let display_header = header.into_iter().map(|h| format!(\"{}\", h)).join(\"|\");\n        tracing::info!(target: \"load_query\", \"\n{display_header}\");\n        output.push('|');\n        output.push_str(&display_header);\n        output.push('|');\n        output.push('\n');\n        let divider = format!(\n            \"|{}\",\n            \"-\".chars()\n                .cycle()\n                .take(5)\n                .chain(\"|\".chars())\n                .join(\"\")\n                .repeat(cols_num)\n        );\n        output.push_str(&divider);\n        output.push('\n');\n        rows.into_iter()\n            .map(|r| {\n                r.into_iter()\n                    .map(|c| format!(\"{}\", c))\n                    .map(|c| format!(\"{}\", c))\n                    .join(\"|\")\n            })\n            .for_each(|r| {\n                tracing::info!(target: \"load_query\", \"\n{}\", r);\n                output.push('|');\n                output.push_str(&r);\n                output.push('|');\n                output.push('\n');\n            });\n        let outfile_name = \"output.md\";\n        let out_file =\n            std::env::current_dir().map(|d| d.join(\"query\").join(outfile_name));\n        if let Ok(file) = out_file {\n            // Writes to file within `if let`, only handling the error case if needed\n            if let Err(e) = tokio::fs::write(file, output).await {\n                tracing::error!(target: \"load_query\", \"Error writing query output to file {e}\")\n            }\n        }\n    }\n}"
      },
      {
        "name": "scan_for_change",
        "dist": 1.4431078433990479,
        "snippet": "pub(super) async fn scan_for_change(\n    state: &Arc<AppState>, \n    event_bus: &Arc<EventBus>, \n    scan_tx: oneshot::Sender<Option< Vec< std::path::PathBuf >>>\n) -> Result<(), ploke_error::Error> {\n    use ploke_error::Error as PlokeError;\n    let guard = state.system.read().await;\n    // TODO: Make a wrapper type for this and make it a method to get just the crate\n    // name.\n    // 1. Get the currently focused crate name, checking for errors.\n    let crate_path = guard.crate_focus.as_ref().ok_or_else(|| {\n        tracing::error!(\"Missing crate focus, cannot scan unspecified target crate\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is None, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n    let crate_name = crate_path.file_name().and_then(|os_str| os_str.to_str()).ok_or_else(|| { \n        tracing::error!(\"Crate name is empty, cannot scan empty crate name\");\n        let e = PlokeError::from(StateError::MissingCrateFocus {msg: \"Missing crate focus is empty or non-utf8 string, cannot scan unspecified target crate\"});\n        e.emit_warning();\n        e\n    })?;\n\n    tracing::info!(\"scan_for_change in crate_name: {}\", crate_name);\n    // 2. get the files in the target project from the db, with hashes\n    let file_data = state.db.get_crate_files(crate_name)?;\n    tracing::info!(\"file_data: {:#?}\", file_data);\n\n    // 3. scan the files, returning a Vec<Option<FileData>>, where None indicates the file has not\n    //    changed.\n    //  - Note that this does not do anything for those files which may have been added, which will\n    //  be handled in parsing during the IndexFiles event process mentioned in step 5 below.\n    let result = state.io_handle.scan_changes_batch(file_data).await?;\n    let vec_ok = result?;\n\n    if !vec_ok.iter().any(|f| f.is_some()) {\n        // 4. if no changes, send complete in oneshot\n        match scan_tx.send(None) {\n            Ok(()) => {\n                tracing::info!(\"No file changes detected\");\n            },\n            Err(e) => {\n                tracing::error!(\"Error sending parse oneshot from ScanForChange\");\n            }\n        };\n    } else {\n        // 5. if changes, send IndexFiles event (not yet made) or handle here.\n        //  Let's see how far we get handling it here first.\n        //  - Since we are parsing the whole target in any case, we might as well do it\n        //  concurrently. Test sequential appraoch first, then move to be parallel earlier.\n\n        // TODO: Move this into `syn_parser` probably\n        // WARN: Just going to use a quick and dirty approach for now to get proof of concept, then later\n        // on I'll do something more efficient.\n        let ParserOutput { mut merged, tree } = run_parse_no_transform(Arc::clone(&state.db), Some(crate_path.clone()))?;\n\n        // get the filenames to send through the oneshot\n        let changed_filenames = vec_ok.iter().filter_map(\n            |opt| opt.as_ref().map(|f| f.file_path.clone())\n        ).collect_vec();\n        for file in changed_filenames.iter() {\n            let filename = format!(\"{}\", file.display());\n            tracing::info!(target:\"file_hashes\", \"Checking for details on {}\", filename);\n            let query_res = state.db.get_path_info(&filename)?;\n            tracing::info!(target:\"file_hashes\", \"headers:\n{}\", query_res.headers.iter().join(\", \") );\n            let rows = query_res.rows.iter().map(|r| r.iter().join(\", \")).join(\"\n\");\n            tracing::info!(target:\"file_hashes\", \"rows:\n {}\", rows);\n        }\n        // WARN: Half-assed implementation, this should be a recurisve function instead of simple\n        // collection.\n        //  - coercing into ModuleNodeId with the test method escape hatch, do properly\n        let module_uuids = vec_ok.into_iter().filter_map(|f| f.map(|i| i.id));\n        let module_ids = module_uuids.clone().map(|uid| \n            ModuleNodeId::new_test(NodeId::Synthetic(uid)));\n        // let module_ids = vec_ok.into_iter().filter_map(|f| f.map(|id| \n        //     ModuleNodeId::new_test(NodeId::Synthetic(id.id))));\n        let module_set: HashSet<ModuleNodeId> = module_ids.collect();\n\n        let any_node_mod_set: Vec<AnyNodeId> = module_set.iter().map(|m_id| m_id.as_any()).collect();\n        let printable_union_items = printable_nodes(&merged, any_node_mod_set.iter());\n        tracing::info!(\"Nodes in file set has count: {}\nitems:\n{}\", module_set.len(),\n            printable_union_items);\n\n        print_module_set(&merged, &tree, &module_set);\n\n        // NOTE: Better implementation to get all nodes in the target files that is recursive\n        let mut full_mod_set: HashSet<AnyNodeId> = HashSet::new();\n        for mod_id in module_set.iter() {\n            full_mod_set = mods_in_file(*mod_id, full_mod_set, &tree);\n            // full_mod_set.insert(mod_id.as_any());\n            let printable_nodes = printable_nodes(&merged, full_mod_set.iter());\n            tracing::info!(\"recursive printable nodes for module_id:\n{}\n{}\", mod_id, printable_nodes);\n        }\n        fn mods_in_file(current: ModuleNodeId, mut mods: HashSet<AnyNodeId>, tree: &ModuleTree) -> HashSet<AnyNodeId> {\n            let start_len = mods.len();\n            if let Some(tree_rels) = tree.get_iter_relations_from(&current.as_any()).map(|it| it.filter(|r| r.rel().is_contains())) {\n                for tree_rel in tree_rels {\n                    let maybe_next = tree_rel.rel().target();\n                    mods.insert(maybe_next);\n                if tree.get_iter_relations_from(&maybe_next).is_some_and(|mut trels| trels.any(|tr| tr.rel().is_contains())) {\n                        let next_mod: ModuleNodeId = maybe_next.try_into()\n                            .expect(\"Invariant Violated: Contains should only be from ModuleNode -> PrimaryNode, found other\");\n                        mods = mods_in_file(next_mod, mods, tree);\n                    }\n                }\n            }\n            mods\n        }\n\n        // Gets all items that are contained by the modules.\n        //  - May be missing some of the secondary node types like params, etc\n        let item_set: HashSet<AnyNodeId> = module_set.iter()\n            .filter_map(|id| tree.modules().get(id))\n            .filter_map(|m| m.items())\n            .flat_map(|items| items.iter().copied().map(|id| id.as_any()))\n            .collect();\n        let union = full_mod_set.iter().copied().map(|m_id| m_id.as_any())\n            .chain(module_set.iter().copied().map(|m_id| m_id.as_any()))\n            .collect::<HashSet<AnyNodeId>>()\n            // let union = module_set.iter().copied().map(|m_id| m_id.as_any()).collect::<HashSet<AnyNodeId>>()\n            .union(&item_set).copied().collect::<HashSet<AnyNodeId>>();\n            // for now filter out anything that isn't one of the PrimaryNode types\n        let filtered_union = union.into_iter().filter(|&id| PrimaryNodeId::try_from(id).is_ok())\n            // .filter(|&id| !matches!(id, AnyNodeId::Import(_)) || !matches!(id, AnyNodeId::Impl(_)))\n            .collect::<HashSet<AnyNodeId>>();\n\n        tracing::info!(\"Nodes in union set:\");\n        let printable_union_items = printable_nodes(&merged, filtered_union.iter());\n        tracing::info!(\"prinable_union_items:\n{}\", printable_union_items);\n        // filter relations\n        merged.graph.relations.retain(|r| filtered_union.contains(&r.source()) || filtered_union.contains(&r.target()));\n        // filter nodes\n        merged.retain_all(filtered_union);\n        // merged.graph.modules.retain(|m| m.is_file_based() || m.is_inline());\n\n        transform_parsed_graph(&state.db, merged, &tree).inspect_err(|e| {\n            tracing::error!(\"Error transforming partial graph into database:\n{e}\");\n        })?;\n\n        for file_id in module_uuids {\n            for node_ty in NodeType::primary_nodes() {\n                tracing::info!(\"Retracting type: {}\", node_ty.relation_str());\n                let query_res = state.db.retract_embedded_files(file_id, node_ty)\n                    .inspect_err(|e| tracing::error!(\"Error in retract_embed_files: {e}\"))?;\n                tracing::info!(\"Raw return of retract_embedded_files:\n{:?}\", query_res);\n                let to_print = query_res.rows.iter().map(|r| r.iter().join(\" | \")).join(\"\n\");\n                tracing::info!(\"Return of retract_embedded_files:\n{}\", to_print);\n            }\n        }\n\n        tracing::info!(\"Finishing scanning, sending message to reindex workspace\");\n        event_bus.send(AppEvent::System(SystemEvent::ReIndex { workspace: crate_name.to_string() }));\n        let _ = scan_tx.send(Some( changed_filenames ));\n        // TODO: Add validation step here.\n    }\n    //\n\n    Ok(())\n}"
      },
      {
        "name": "run_parse",
        "dist": 1.4949589967727661,
        "snippet": "pub fn run_parse(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<(), ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    ploke_transform::transform::transform_parsed_graph(&db, merged, &tree)?;\n    tracing::info!(\n        \"{}: Parsing and Database Transform Complete\",\n        \"Setup\".log_step()\n    );\n    Ok(())\n}"
      },
      {
        "name": "init_tracing",
        "dist": 1.522981882095337,
        "snippet": "pub fn init_tracing() -> WorkerGuard {\n    let filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info,ploke_db=info,cozo=error,tokenizer=error\"));  // Default to 'info' level\n    \n    // File appender with custom timestamp format\n    let log_dir = \"logs\";\n    std::fs::create_dir_all(log_dir).expect(\"Failed to create logs directory\");\n    let file_appender = tracing_appender::rolling::daily(log_dir, \"ploke.log\");\n    let (non_blocking_file, file_guard) = tracing_appender::non_blocking(file_appender);\n    \n    // Common log format builder\n    let fmt_layer = fmt::layer()\n        .with_target(true)\n        .with_level(true)\n        .with_thread_ids(true)\n        .with_span_events(FmtSpan::CLOSE);  // Capture span durations\n    \n    let file_subscriber = fmt_layer\n        .with_writer(non_blocking_file)\n        .pretty()\n        .with_ansi(false);\n\n    tracing_subscriber::registry()\n        .with(filter)\n        .with(file_subscriber)\n        .init();\n\n    file_guard\n}"
      },
      {
        "name": "find_file_by_prefix",
        "dist": 1.5347144603729248,
        "snippet": "pub async fn find_file_by_prefix(\n    dir: impl AsRef<std::path::Path>,\n    prefix: &str,\n) -> std::io::Result<Option<std::path::PathBuf>> {\n    let mut entries = fs::read_dir(dir).await?;\n    while let Some(entry) = entries.next_entry().await? {\n        let name = entry.file_name();\n        if let Some(name_str) = name.to_str() {\n            tracing::debug!(\"\nchecking file to load:                  | {name_str}\nname_str.starts_with(prefix):           | {}\nname_str.len() == prefix.len() + 1 + 36 | {}\n\", name_str.starts_with(prefix), name_str.len() == prefix.len() + 1 + 36\n            );\n            if name_str.starts_with(prefix) && name_str.len() == prefix.len() + 1 + 36 {\n                tracing::debug!(\"passes checks: {}\", name_str);\n                // fixture_tracking_hash_aa1d3812-abb4-5d05-a69f-fe80aa856e3d\n                // prefix + '_' + 36-char UUID\n                return Ok(Some(entry.path()));\n            }\n        }\n    }\n    Ok(None)\n}"
      },
      {
        "name": "switch_model",
        "dist": 1.5433225631713867,
        "snippet": "pub(super) async fn switch_model(state: &Arc<AppState>, event_bus: &Arc<EventBus>, alias_or_id: String) {\n    tracing::debug!(\"inside StateCommand::SwitchModel {}\", alias_or_id);\n\n    let mut cfg = state.config.write().await;\n    if cfg.provider_registry.set_active(&alias_or_id) {\n        tracing::debug!(\n            \"sending AppEvent::System(SystemEvent::ModelSwitched {}\n                        Trying to find cfg.provider_registry.get_active_provider(): {:#?}\",\n            alias_or_id,\n            cfg.provider_registry.get_active_provider(),\n        );\n        let actual_model = cfg\n            .provider_registry\n            .get_active_provider()\n            .map(|p| p.model.clone())\n            .unwrap_or_else(|| alias_or_id.clone());\n        event_bus.send(AppEvent::System(SystemEvent::ModelSwitched(\n            actual_model, // Using actual model ID\n        )));\n    } else {\n        tracing::debug!(\"Sending AppEvent::Error(ErrorEvent {}\", alias_or_id);\n        event_bus.send(AppEvent::Error(ErrorEvent {\n            message: format!(\"Unknown model '{}'\", alias_or_id),\n            severity: ErrorSeverity::Warning,\n        }));\n    }\n}"
      },
      {
        "name": "run_parse_no_transform",
        "dist": 1.6303929090499878,
        "snippet": "pub fn run_parse_no_transform(db: Arc<Database>, target_dir: Option<PathBuf>) -> Result<ParserOutput, ploke_error::Error> {\n    use syn_parser::utils::LogStyle;\n\n    let target = resolve_target_dir(target_dir)?;\n    tracing::info!(\n        \"{}: run the parser on {}\",\n        \"Parse\".log_step(),\n        target.display()\n    );\n\n    let discovery_output =\n        run_discovery_phase(&target, &[target.clone()]).map_err(ploke_error::Error::from)?;\n\n    let results: Vec<Result<ParsedCodeGraph, SynParserError>> =\n        analyze_files_parallel(&discovery_output, 0);\n\n    let graphs: Vec<_> = results\n        .into_iter()\n        .collect::<Result<_, _>>()\n        .map_err(ploke_error::Error::from)?;\n\n    let mut merged = ParsedCodeGraph::merge_new(graphs)?;\n    let tree = merged.build_tree_and_prune()?;\n    Ok( ParserOutput {merged, tree} )\n}"
      },
      {
        "name": "insert_openrouter",
        "dist": 1.630879282951355,
        "snippet": "/// Helper to reduce boilerplate when adding new OpenRouter defaults.\n fn insert_openrouter(\n     map: &mut HashMap<String, ProviderConfig>,\n     id: &str,\n     model: &str,\n     temperature: Option< f32 >,\n ) {\n     map.insert(\n         id.to_string(),\n         ProviderConfig {\n             id: id.to_string(),\n             api_key: String::new(), // will be filled from env or user config\n             api_key_env: Some(\"OPENROUTER_API_KEY\".to_string()),\n             base_url: \"https://openrouter.ai/api/v1\".to_string(),\n             model: model.to_string(),\n             display_name: Some(model.to_string()),\n             provider_type: ProviderType::OpenRouter,\n             llm_params: Some(crate::llm::LLMParameters {\n                 temperature,\n                 model: model.to_string(),\n                 ..Default::default()\n             })\n         },\n     );\n }"
      },
      {
        "name": "layout_statusline",
        "dist": 1.655109167098999,
        "snippet": "/// Creates a horizontal layout split into equal ratio divisions for status line components.\n///\n/// # Arguments\n/// * `divs` - Number of equal-width divisions to create (minimum 1)\n/// * `area` - Rectangular area to divide\n///\n/// # Returns\n/// Rc<[Rect]> containing the split areas for efficient rendering\n///\n/// # Example\n/// ```\n/// use ratatui::layout::Rect;\n/// use ploke_tui::utils::layout::layout_statusline;\n/// // Split a 100px wide area into 3 sections (33%, 66%, 100% of remaining space)\n/// let area = Rect::new(0, 0, 10, 10);\n/// let layout = layout_statusline(3, area);\n/// ```\npub fn layout_statusline(divs: u32, area: Rect) -> std::rc::Rc<[ratatui::layout::Rect]> {\n    let constraints = (1..=divs).map(|x| Constraint::Ratio(x, divs));\n    Layout::default()\n        .direction(Direction::Horizontal)\n        .constraints(constraints)\n        .split(area)\n}"
      },
      {
        "name": "print_module_set",
        "dist": 1.6717092990875244,
        "snippet": "fn print_module_set(\n    merged: &syn_parser::ParsedCodeGraph,\n    tree: &ModuleTree,\n    module_set: &HashSet<ModuleNodeId>,\n) {\n    let item_map_printable = module_set\n        .iter()\n        .filter_map(|id| {\n            tree.modules()\n                .get(id)\n                .filter(|m| m.items().is_some())\n                .map(|m| {\n                    let module = format!(\n                        \"name: {} | is_file: {} | id: {}\",\n                        m.name,\n                        m.id.as_any(),\n                        m.is_file_based()\n                    );\n                    let items = m\n                        .items()\n                        .unwrap()\n                        .iter()\n                        .filter_map(|item_id| {\n                            merged\n                                .find_any_node(item_id.as_any())\n                                .map(|n| format!(\"\\tname: {} | id: {}\", n.name(), n.any_id()))\n                        })\n                        .join(\"\n\");\n                    format!(\"{}\n{}\", module, items)\n                })\n        })\n        .join(\"\n\");\n    tracing::info!(\"--- items by module ---\n{}\", item_map_printable);\n}"
      },
      {
        "name": "create_mock_db",
        "dist": 1.7128124237060547,
        "snippet": "pub fn create_mock_db(num_unindexed: usize) -> Arc<Database> {\n    let storage = MemStorage::default();\n    let db = Arc::new(Database::new(Db::new(storage).unwrap()));\n    \n    let script = r#\"\n    ?[id, path, tracking_hash, start_byte, end_byte] <- [\n        $unindexed,\n    ]\n\n    :create embedding_nodes {\n        id => Uuid\n    }\n    \"#;\n    \n    todo!(\"define and insert params, ensure db.run_script works correctly\");\n    \n    // db.run_script(script, params, ScriptMutability::Mutable).unwrap();\n    #[allow(unreachable_code)]\n    db\n}"
      },
      {
        "name": "printable_nodes",
        "dist": 1.7271828651428223,
        "snippet": "fn printable_nodes<'a>(\n    merged: &syn_parser::ParsedCodeGraph,\n    union: impl Iterator<Item = &'a AnyNodeId>,\n) -> String {\n    let mut printable_union_items = String::new();\n    for id in union.into_iter() {\n        if let Some(node) = merged.find_any_node(*id) {\n            let printable_node = format!(\"name: {} | id: {}\n\", node.name(), id);\n            printable_union_items.push_str(&printable_node);\n        }\n    }\n    printable_union_items\n}"
      },
      {
        "name": "wait_on_oneshot",
        "dist": 1.7272870540618896,
        "snippet": "async fn wait_on_oneshot<T>(\n    new_msg_id: Uuid,\n    completion_rx: oneshot::Receiver<T>,\n) -> ControlFlow<()> {\n    match completion_rx.await {\n        Ok(_) => {\n            tracing::trace!(\"UserMessage received new_msg_id: {}\", new_msg_id)\n        }\n        Err(e) => {\n            tracing::warn!(\n                \"SendUserMessage dropped before EmbedMessage process received it for new_msg_id: {}\",\n                new_msg_id\n            );\n            return ControlFlow::Break(());\n        }\n    }\n    ControlFlow::Continue(())\n}"
      },
      {
        "name": "set_global_event_bus",
        "dist": 1.7325828075408936,
        "snippet": "/// Set the global event bus for error handling\npub async fn set_global_event_bus(event_bus: Arc<EventBus>) {\n    *GLOBAL_EVENT_BUS.lock().await = Some(event_bus);\n}"
      },
      {
        "name": "atomic_write",
        "dist": 1.7467148303985596,
        "snippet": "/// Atomically writes file contents using tempfile and rename\npub(crate) async fn atomic_write(\n    path: &std::path::Path,\n    content: String,\n) -> Result<(), std::io::Error> {\n    let dir = path\n        .parent()\n        .unwrap_or_else(|| std::path::Path::new(\".\"));\n    let mut temp = NamedTempFile::new_in(dir)?;\n    temp.write_all(content.as_bytes())?;\n    // Map PersistError into a plain io::Error to satisfy the return type\n    temp.persist(path)\n        .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;\n    Ok(())\n}"
      },
      {
        "name": "test_resolve_target_dir_without_user_path",
        "dist": 1.7610689401626587,
        "snippet": "#[test]\n    fn test_resolve_target_dir_without_user_path() {\n        let expected_path = env::current_dir().unwrap();\n        let result = resolve_target_dir(None);\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_user_path",
        "dist": 1.7705011367797852,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_user_path() {\n        let expected_path = PathBuf::from(\"/tmp/test/path\");\n        let result = resolve_target_dir(Some(expected_path.clone()));\n        assert_eq!(result.unwrap(), expected_path);\n    }"
      },
      {
        "name": "test_resolve_target_dir_with_empty_path",
        "dist": 1.7714093923568726,
        "snippet": "#[test]\n    fn test_resolve_target_dir_with_empty_path() {\n        let empty_path = PathBuf::new();\n        let result = resolve_target_dir(Some(empty_path.clone()));\n        assert_eq!(result.unwrap(), empty_path);\n    }"
      },
      {
        "name": "default_true",
        "dist": 1.7799961566925049,
        "snippet": "fn default_true() -> bool {\n    true\n}"
      },
      {
        "name": "kind_to_str",
        "dist": 1.7953797578811646,
        "snippet": "fn kind_to_str<'a>(msg: &'a &'a Message) -> &'a str {\n    match msg.kind {\n        MessageKind::User => \"user\",\n        MessageKind::Assistant => \"assistant\",\n        MessageKind::System => \"system\",\n        MessageKind::Tool => todo!(),\n        MessageKind::SysInfo => \"sysinfo\",\n    }\n}"
      },
      {
        "name": "default_base_url",
        "dist": 1.7997255325317383,
        "snippet": "fn default_base_url() -> String {\n    \"https://openrouter.ai/api/v1\".to_string()\n}"
      },
      {
        "name": "chat_url",
        "dist": 1.80007004737854,
        "snippet": "fn chat_url() -> String {\n    \"https://openrouter.ai/api/v1/chat/completions\".to_string()\n}"
      },
      {
        "name": "default_active_provider",
        "dist": 1.804086446762085,
        "snippet": "pub fn default_active_provider() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "measure_messages",
        "dist": 1.8073630332946777,
        "snippet": "#[instrument(skip(renderable_msg), level = \"trace\")]\npub fn measure_messages(\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    selected_index: Option<usize>,\n) -> (u16, Vec<u16>) {\n    // Compute per-message heights and total height for the current frame.\n    let mut heights: Vec<u16> = Vec::with_capacity(renderable_msg.len());\n    let mut total_height = 0u16;\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        // Always reserve a 1-column gutter for the selection bar to keep heights stable.\n        let eff_w = conversation_width.saturating_sub(1);\n        let h = calc_height(&msg.content, eff_w);\n        heights.push(h);\n        total_height = total_height.saturating_add(h);\n    }\n    (total_height, heights)\n}"
      },
      {
        "name": "emit_error_event",
        "dist": 1.8134465217590332,
        "snippet": "/// Emit an error event to the global event bus\npub async fn emit_error_event(message: String, severity: ErrorSeverity) {\n    if let Some(event_bus) = GLOBAL_EVENT_BUS.lock().await.as_ref() {\n        event_bus.send(AppEvent::Error(ErrorEvent { message, severity }));\n    }\n}"
      },
      {
        "name": "default_model_id",
        "dist": 1.8142423629760742,
        "snippet": "pub fn default_model_id() -> String {\n    \"kimi-k2\".to_string()\n}"
      },
      {
        "name": "truncate_string",
        "dist": 1.8142926692962646,
        "snippet": "pub fn truncate_string(s: &str, max: usize) -> String {\n    if s.len() > max {\n        format!(\"{}...\", &s[..std::cmp::min(s.len(), max)])\n    } else {\n        s.to_string()\n    }\n}"
      },
      {
        "name": "display_file_info",
        "dist": 1.8157483339309692,
        "snippet": "fn display_file_info(file: Option<&Arc<std::path::PathBuf>>) -> String {\n            file.map(|f| f.display().to_string()).unwrap_or(\"File not found.\".to_string())\n        }"
      },
      {
        "name": "truncate_uuid",
        "dist": 1.8176639080047607,
        "snippet": "fn truncate_uuid(id: Uuid) -> String {\n    id.to_string().chars().take(8).collect()\n}"
      },
      {
        "name": "render_messages",
        "dist": 1.8190888166427612,
        "snippet": "#[instrument(skip(frame, renderable_msg, heights), level = \"trace\")]\npub fn render_messages(\n    frame: &mut Frame,\n    renderable_msg: &[RenderableMessage],\n    conversation_width: u16,\n    conversation_area: Rect,\n    offset_y: u16,\n    heights: &[u16],\n    selected_index: Option<usize>,\n) {\n    // 1) Clamp offset\n    let viewport_height = conversation_area.height;\n    let total_height: u16 = heights.iter().copied().fold(0u16, |acc, h| acc.saturating_add(h));\n    let clamped_offset_y = offset_y.min(total_height.saturating_sub(viewport_height));\n\n    // 2) Render visible slice\n    let mut y_screen = 0u16;\n    let mut y_virtual = 0u16;\n\n    for (idx, msg) in renderable_msg.iter().enumerate() {\n        let height = heights[idx];\n        let is_selected = selected_index == Some(idx);\n        let base_style = match msg.kind {\n            MessageKind::User => Style::new().blue(),\n            MessageKind::Assistant => Style::new().green(),\n            MessageKind::System => Style::new().cyan(),\n            MessageKind::SysInfo => Style::new().magenta(),\n            _ => Style::new().white(),\n        };\n\n        if y_virtual + height <= clamped_offset_y {\n            y_virtual = y_virtual.saturating_add(height);\n            continue;\n        }\n\n        // Use the same effective width as in height calc: always reserve 1-column gutter.\n        let eff_w = conversation_width.saturating_sub(1);\n        let wrapped = textwrap::wrap(&msg.content, eff_w as usize);\n        let bar = Span::styled(\"\", base_style.fg(Color::White));\n\n        // If offset lands inside this message, skip top lines so we dont waste space\n        let mut start_line = 0usize;\n        if clamped_offset_y > y_virtual {\n            start_line = (clamped_offset_y - y_virtual) as usize;\n        }\n        for line in wrapped.iter().skip(start_line) {\n            let mut spans = Vec::with_capacity(2);\n            if is_selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(line.as_ref()));\n            let para = Paragraph::new(Line::from(spans)).style(base_style);\n\n            let area = Rect::new(\n                conversation_area.x + 1,\n                conversation_area.y + y_screen,\n                conversation_width,\n                1,\n            );\n            frame.render_widget(para, area);\n            y_screen = y_screen.saturating_add(1);\n            if y_screen >= viewport_height {\n                return;\n            }\n        }\n        y_virtual = y_virtual.saturating_add(height);\n    }\n}"
      },
      {
        "name": "calculate_message_height",
        "dist": 1.8375695943832397,
        "snippet": "fn calculate_message_height(content: &str, width: u16) -> u16 {\n    let wrapped = textwrap::wrap(content, width as usize);\n    wrapped.len() as u16\n}"
      },
      {
        "name": "calc_height",
        "dist": 1.8410754203796387,
        "snippet": "#[instrument(skip(content), level = \"trace\")]\nfn calc_height(content: &str, width: u16) -> u16 {\n    textwrap::wrap(content, width as usize).len() as u16\n}"
      },
      {
        "name": "render_one_message",
        "dist": 1.8658407926559448,
        "snippet": "/// Returns `(lines_consumed, Vec<Line<'a>>)` borrowing the wrapped text\n#[instrument(skip(content))]\nfn render_one_message<'a>(\n    content: &'a str,\n    width: u16,\n    style: Style,\n    selected: bool,\n) -> (u16, Vec<Line<'a>>) {\n    let wrapped = textwrap::wrap(content, width.saturating_sub(2) as usize);\n    let bar = Span::styled(\"\", style.fg(Color::White));\n\n    let lines: Vec<Line<'a>> = wrapped\n        .into_iter()\n        .map(|s| {\n            let mut spans = Vec::with_capacity(2);\n            if selected {\n                spans.push(bar.clone());\n            }\n            spans.push(Span::raw(s));\n            Line::from(spans)\n        })\n        .collect();\n\n    (lines.len() as u16, lines)\n}"
      },
      {
        "name": "default_model",
        "dist": 1.8903019428253174,
        "snippet": "pub fn default_model() -> String {\n    \"moonshotai/kimi-k2\".to_string()\n}"
      }
    ]
  }
]