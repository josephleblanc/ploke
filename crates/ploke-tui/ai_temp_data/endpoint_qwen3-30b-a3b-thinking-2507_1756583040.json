{
  "data": {
    "architecture": {
      "input_modalities": [
        "text"
      ],
      "instruct_type": "deepseek-v3.1",
      "modality": "text->text",
      "output_modalities": [
        "text"
      ],
      "tokenizer": "DeepSeek"
    },
    "created": 1755779628,
    "description": "DeepSeek-V3.1 is a large hybrid reasoning model (671B parameters, 37B active) that supports both thinking and non-thinking modes via prompt templates. It extends the DeepSeek-V3 base with a two-phase long-context training process, reaching up to 128K tokens, and uses FP8 microscaling for efficient inference. Users can control the reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)\n\nThe model improves tool use, code generation, and reasoning efficiency, achieving performance comparable to DeepSeek-R1 on difficult benchmarks while responding more quickly. It supports structured tool calling, code agents, and search agents, making it suitable for research, coding, and agentic workflows. \n\nIt succeeds the [DeepSeek V3-0324](/deepseek/deepseek-chat-v3-0324) model and performs well on a variety of tasks.",
    "endpoints": [
      {
        "context_length": 163840,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "Chutes | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.0000008",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.0000002",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "Chutes",
        "quantization": null,
        "status": 0,
        "supported_parameters": [
          "tools",
          "tool_choice",
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ],
        "supports_implicit_caching": false,
        "tag": "chutes",
        "uptime_last_30m": 99.95828118481434
      },
      {
        "context_length": 163840,
        "max_completion_tokens": 131072,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "SiliconFlow | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.0000011",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.00000027",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "SiliconFlow",
        "quantization": "fp8",
        "status": 0,
        "supported_parameters": [
          "reasoning",
          "include_reasoning",
          "temperature",
          "top_p",
          "top_k",
          "frequency_penalty"
        ],
        "supports_implicit_caching": false,
        "tag": "siliconflow/fp8",
        "uptime_last_30m": 98.4390243902439
      },
      {
        "context_length": 163840,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "DeepInfra | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.000001",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.0000003",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "DeepInfra",
        "quantization": "fp4",
        "status": 0,
        "supported_parameters": [
          "tools",
          "tool_choice",
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "top_k",
          "seed",
          "min_p",
          "response_format"
        ],
        "supports_implicit_caching": false,
        "tag": "deepinfra/fp4",
        "uptime_last_30m": 99.96251874062968
      },
      {
        "context_length": 65535,
        "max_completion_tokens": 32768,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "AtlasCloud | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.0000015",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.0000005",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "AtlasCloud",
        "quantization": "fp8",
        "status": 0,
        "supported_parameters": [
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p"
        ],
        "supports_implicit_caching": false,
        "tag": "atlas-cloud/fp8",
        "uptime_last_30m": 99.8888888888889
      },
      {
        "context_length": 128000,
        "max_completion_tokens": 128000,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "WandB | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.00000165",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.00000055",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "WandB",
        "quantization": "fp8",
        "status": 0,
        "supported_parameters": [
          "tools",
          "tool_choice",
          "reasoning",
          "include_reasoning",
          "structured_outputs",
          "response_format",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "repetition_penalty",
          "frequency_penalty",
          "presence_penalty",
          "stop",
          "seed"
        ],
        "supports_implicit_caching": false,
        "tag": "wandb/fp8",
        "uptime_last_30m": 100
      },
      {
        "context_length": 163840,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "GMICloud | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.00000165",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.00000055",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "GMICloud",
        "quantization": "fp8",
        "status": 0,
        "supported_parameters": [
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "seed"
        ],
        "supports_implicit_caching": false,
        "tag": "gmicloud/fp8",
        "uptime_last_30m": 98.87892376681614
      },
      {
        "context_length": 163840,
        "max_completion_tokens": 163840,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "Novita | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.00000166",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.00000055",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "Novita",
        "quantization": null,
        "status": 0,
        "supported_parameters": [
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logit_bias"
        ],
        "supports_implicit_caching": false,
        "tag": "novita",
        "uptime_last_30m": 99.56521739130434
      },
      {
        "context_length": 163840,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "Fireworks | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.00000168",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.00000056",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "Fireworks",
        "quantization": null,
        "status": 0,
        "supported_parameters": [
          "tools",
          "tool_choice",
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format",
          "structured_outputs"
        ],
        "supports_implicit_caching": false,
        "tag": "fireworks",
        "uptime_last_30m": 99.98211411196566
      },
      {
        "context_length": 163840,
        "max_completion_tokens": 163840,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "Parasail | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.00000165",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.00000064",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "Parasail",
        "quantization": "fp8",
        "status": 0,
        "supported_parameters": [
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "frequency_penalty",
          "min_p",
          "presence_penalty",
          "repetition_penalty",
          "seed",
          "stop",
          "top_k",
          "logit_bias"
        ],
        "supports_implicit_caching": false,
        "tag": "parasail/fp8",
        "uptime_last_30m": 99.73154362416108
      },
      {
        "context_length": 32768,
        "max_completion_tokens": 7168,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "SambaNova | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.0000045",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "internal_reasoning": "0",
          "prompt": "0.000003",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "SambaNova",
        "quantization": null,
        "status": 0,
        "supported_parameters": [
          "reasoning",
          "include_reasoning",
          "max_tokens",
          "temperature",
          "top_p",
          "top_k",
          "stop"
        ],
        "supports_implicit_caching": false,
        "tag": "sambanova",
        "uptime_last_30m": null
      },
      {
        "context_length": 131072,
        "max_completion_tokens": 8192,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "DeepSeek | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.0000011",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "input_cache_read": "0.00000007",
          "internal_reasoning": "0",
          "prompt": "0.00000027",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "DeepSeek",
        "quantization": null,
        "status": 0,
        "supported_parameters": [
          "tools",
          "tool_choice",
          "reasoning",
          "include_reasoning",
          "response_format",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logprobs",
          "top_logprobs"
        ],
        "supports_implicit_caching": true,
        "tag": "deepseek",
        "uptime_last_30m": 99.9370673379484
      },
      {
        "context_length": 131072,
        "max_completion_tokens": 64000,
        "max_prompt_tokens": null,
        "model_name": "DeepSeek: DeepSeek V3.1",
        "name": "DeepSeek | deepseek/deepseek-chat-v3.1",
        "pricing": {
          "completion": "0.0000011",
          "discount": 0,
          "image": "0",
          "image_output": "0",
          "input_cache_read": "0.00000007",
          "internal_reasoning": "0",
          "prompt": "0.00000027",
          "request": "0",
          "web_search": "0"
        },
        "provider_name": "DeepSeek",
        "quantization": null,
        "status": 0,
        "supported_parameters": [
          "tools",
          "tool_choice",
          "reasoning",
          "include_reasoning",
          "response_format",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "logprobs",
          "top_logprobs"
        ],
        "supports_implicit_caching": true,
        "tag": "deepseek",
        "uptime_last_30m": null
      }
    ],
    "id": "deepseek/deepseek-chat-v3.1",
    "name": "DeepSeek: DeepSeek V3.1"
  }
}