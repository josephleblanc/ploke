Title: OpenRouter Tool-Use E2E Validation Plan

Objectives and Scope
- Validate the full tool-call pipeline end to end using `ploke-tui` against OpenRouter:
  - Event emission/handling in the app (Requested → Completed/Failed) with correct correlation ids.
  - Request shapes (chat/completions) including tools, tool_choice, and provider routing hints.
  - Endpoint discovery/selection and tool capability signaling.
  - Response handling and deserialization to strongly-typed structs; no missing fields or type mismatches.
  - GAT-based tool deserialization/dispatch executes and returns well-formed outputs.
  - Tool outputs are injected back into the conversation and the second leg completes.
  - Happy-paths and fail-states produce expected outcomes and actionable diagnostics.
- Default to offline tests; gate live API tests behind `--features live_api_tests` (and `test_harness` when applicable). Do not report live readiness without exercising the live path.
- Evidence discipline: Persist artifacts under `target/test-output/` and `ai_temp_data/live/` as appropriate; summarize pass/fail counts in reports (not raw logs).

Proposed Steps (with Rationale and Acceptance Criteria)
1) Inventory current coverage and align targets
   - Rationale: Reuse and build on existing tests to avoid duplication and ensure continuity with prior work.
   - Actions:
     - Review and reference: `crates/ploke-tui/tests/e2e_tool_calls.rs`, `tests/live_openrouter_tools.rs`, `src/llm/session.rs` tests, and live/gated tests in `openrouter/*` modules.
     - Confirm gating defaults in `crates/ploke-tui/Cargo.toml` and environment feature flags.
   - Acceptance:
     - A short mapping of which bullets below each existing test covers is captured in the impl log.

2) Strong typing: request/response shape assertions (offline)
   - Rationale: Ensure we use strongly typed structs/enums at boundaries (no stringly typed plumbing).
   - Actions:
     - Add focused unit tests for `CompReq` serialization with tools/tool_choice and provider preferences.
     - Expand deserialization tests for `Endpoint(s)Response` to assert numeric and enum types (e.g., `u32`, `f32`, enums) and presence of key fields.
   - Acceptance:
     - Tests pass without panics; serde errors fail tests with crisp causes.
     - No lossy conversions or `String` stand-ins where numeric/enums are expected.

3) Event flow: dispatcher and GAT tools (offline)
   - Rationale: Validate `ToolEvent::Requested → SystemEvent::ToolCallCompleted/Failed` roundtrips and the GAT path for deserialization.
   - Actions:
     - Extend `e2e_tool_calls.rs` to include an error-path case (malformed args) asserting `ToolCallFailed` with helpful error text.
     - Add a GAT dispatch test for each tool (`request_code_context`, `apply_code_edit`, `get_file_metadata`) ensuring Completed emits and payloads are valid JSON for the tool result structs.
   - Acceptance:
     - For each tool: observe exactly one Completed event for valid inputs; Failed for malformed inputs with actionable messages.

4) RequestSession loop: two-leg tool cycle (offline harness)
   - Rationale: Exercise the `RequestSession` event-waiting logic without network by simulating ToolCompleted via the event bus.
   - Actions:
     - Add a unit/integration test using `RequestSession` where a synthetic assistant “tool_calls” is simulated by directly enqueuing a `Requested` and then a matching `Completed` event (no network). Validate that the second leg proceeds to a final message.
   - Acceptance:
     - The session appends the tool result message and returns a non-empty final content string.
     - Timeout/error paths produce `LlmError` variants with clear guidance.

5) Live smoke: endpoints and tool-capable request (gated)
   - Rationale: Verify that the live endpoints path works and that our shapes are accepted in the wild.
   - Actions:
     - Keep `tests/live_openrouter_tools.rs` to build a minimal tool-enabled request; persist request/response under `ai_temp_data/live/`.
     - Add an assertion for at least one `tool_calls` presence (or record a “not validated” marker file if absent) per Live Gates policy.
 - Acceptance:
   - HTTP success; artifacts persisted; explicit evidence of tool_calls or explicit “not validated”.

6) Live two-leg tool roundtrip: RequestSession with TEST_APP (gated)
   - Rationale: Validate the full loop: assistant returns tool_calls; dispatcher executes local tool(s); tool outputs are sent back; final assistant content is returned.
   - Actions:
     - Add a new live test `tests/live_tool_roundtrip.rs` (cfg: `all(feature = "live_api_tests", feature = "test_harness")`) that:
       - Uses `test_harness::TEST_APP`/`get_state()` for realistic state and DB-backed RAG.
       - Builds tools with `RequestCodeContextGat::tool_def()` and forces tool_choice.
       - Runs `RequestSession::run()` and subscribes to events to count Requested/Completed.
       - Persists artifacts to `target/test-output/openrouter_e2e/` (request, response excerpts, counts).
  - Acceptance:
    - Observed at least one Requested and one Completed; Completed payload is valid JSON for the tool’s result.
    - Final assistant content is non-empty and HTTP statuses are success.
    - Skips cleanly when `OPENROUTER_API_KEY` is unset.

7) Fail-state validation (gated)
   - Rationale: Ensure robust guidance and 404 tooling fallback behavior.
   - Actions:
     - Add a live test that intentionally sets an invalid/unavailable provider slug with `tools-only` set, expecting a 404-like guidance path from `RequestSession`.
  - Acceptance:
    - Test asserts the guidance text includes remediation steps (list providers, pin, tools-only toggle).

8) Live test matrix + metrics (gated) — iterate across prompts/models/tools
   - Rationale: Build a reusable matrix harness to evaluate prompt and tool-instruction effectiveness, and capture latency/performance across models and tools.
   - Actions:
     - Add test helpers to construct tool-enabled requests with variable prompts and tool_choice (auto vs function), and to select a tools-capable provider endpoint per model.
     - Define a set of prompts (min: 2–3) that exercise tool usage explicitly and implicitly, and allow an env override to inject additional prompts.
     - Iterate a matrix over: models (env-driven subset), prompts, tool_choice mode, and provider slug (hinted from endpoints). Control size via `PLOKE_LIVE_MAX_MODELS` / `PLOKE_LIVE_MAX_COMBOS`.
     - Collect metrics: start/end timestamps, duration_ms, HTTP status, response length, presence of `tool_calls`, choices count, and (if present) token usage fields.
     - Persist artifacts per run under `target/test-output/openrouter_matrix/<ts-run>/` with `metrics.jsonl`, `summary.json`, and sampled request/response snapshots.
     - Provide a tiny summarizer to aggregate metrics by model/prompt/tool_choice for quick comparisons.
   - Acceptance:
     - At least one combination observes `tool_calls`, recorded in metrics; combinations without tool_calls are marked as “not validated”.
     - Metrics artifacts exist and include duration and status for all combinations attempted.
     - Helpers make it trivial to add new prompts and models without changing core test logic.

Deliverables
- New/updated tests under `crates/ploke-tui/tests/` and unit tests under relevant modules:
  - Offline: shape assertions, dispatcher/GAT validation, `RequestSession` simulated loop.
  - Live (gated): endpoint smoke and full roundtrip session using TEST_APP.
- No code paths rely on string-typed fields at API edges; types derive Serialize/Deserialize with numeric fields as numeric types, enums for discrete states, tagged unions preferred.
- Implementation log linked to this plan with run instructions, gates, and evidence summary.

Validation Approach
- Offline CI:
  - `cargo test -p ploke-tui` (no network). Summarize pass/fail/ignored counts in impl log.
- Live manual/CI with secrets (gated):
  - `cargo test -p ploke-tui --features live_api_tests` or with default features if already enabled.
  - Required env: `OPENROUTER_API_KEY`; optional: `PLOKE_LIVE_MAX_MODELS`.
  - Evidence: count of tool_calls observed, events observed, roundtrip success; artifacts under `target/test-output/` and `ai_temp_data/live/`.
  - Live Gates discipline: If tool_calls are not observed, mark as “not validated” and do not count as pass for live-readiness.

References
- Workflow guide: `crates/ploke-tui/docs/feature/agent-system/workflows/tool_use_end_to_end.md`
- Harness: `crates/ploke-tui/src/test_harness.rs` and `crates/ploke-tui/tests/harness.rs`
- Strong typing: `crates/ploke-tui/src/llm/openrouter/model_provider.rs`, `crates/ploke-tui/src/tools/*`
- Session loop: `crates/ploke-tui/src/llm/session.rs`

Linkage
- Implementation logs will be named `impl_20250831-215141Z.md` under `docs/plans/agentic-system-plan/impl-plan/` and will reference this plan path.
