# Todo Nov 14, 2025

Note: other planning docs for vector embedding support in `ploke/crates/ploke-tui/docs/active/plans/remote-embedding/`
  - IMPORTANT: All of the planning docs in `remote-embedding` directory that
  reference CozoScript or database scripts, or using Cozo, are extremely
  suspect as they were written by an LLM that does not understand Cozo. The
  below was written by a human who has some experience with Cozo, but still
  needs to be checked/tested, and all Cozo used in the ploke project (such as
  `ploke-db`), has been tested and should be taken as the example to use for
  any Cozo written by LLM/AI. 

1. Work on adding support for remote vector embeddings by migrating our current system of a hardcoded, single vector embedding model, to variable vector length and multiple simultaneous vectors supported

- [ ] Run initial tests to find the baseline of the affected crates, clean up any test failures so we have a clean slate to identify regressions.
  - This migration is surprisingly far-reaching, and since it affects the cozo database, which is a pain in the ass to debug, we need to be careful and catch regressions early.

- [ ] Change database to use variable vector size for embeddings
  - [ ] Move vectors from being stored as fields on nodes to being stored as separate nodes that have an edge pointing to the node, allowing each node to have multiple embeddings from different sources.
    - Q: need to decide whether to use an explicit and separate edge for the embeddings vs using the node_id of the embedding + the embedding identifying name to find the embedding.
      - We can use just the node_id and embedding model identifier here, since
      there should never be a case in which the same node has two embeddings
      from the same model and provider that are valid at the same time (though
      older embeddings may validly be replaced by newer embeddings, which
      inherently happens using Cozo's time-travel functionality)
    - [ ] Change schema for each code item that has an `embedding` field to instead use some kind of key-value pair to store the identifier for the embedding model and the length of the embeddings.
      - data type of value for new field, `embeddings`, tbd
    - [ ] Change the `create_index_warn`, `replace_index_warn`, and other functions that handle embeddings to accept a parameter for the length of the embeddings
    - [ ] Add a schema definition for the new cozo relation, `embeddings`, which should contain at least:
  - [ ] Change transform functions in `ploke-transform` to use new `embeddings` field, initially empty, when transforming intermediate representation of parsed code into the database.
    - e.g. `transform_functions` in `ploke/crates/ingest/ploke-transform/src/transform/functions.rs` and other files in same directory that handle transforms
- [ ] Update call sites of semantic search in `ploke-rag` as needed
- [ ] Update `batch_prompt_search` in `ploke-tui` and other areas touching embeddings as needed

- [ ] Question: Where does the config for the vector embedding selection get applied?
  - Where does the currently used embedding config live? Is it in `RagConfig` (defined in `ploke-rag`), in `SystemStatus` along with `crate_focus` (defined in `ploke-tui`), or elsewhere? What is the best design to ensure all necessary calling functions have access to the setting without blocking?

- [ ] Add utility functions to `ploke-db` to manage the vectors
  - [ ] Add a type to serve as the key for the embeddings with fields for the keys identified in the schema for `embeddings`.
  - [ ] Remove the vectors for a given model + dims + provider from the database

- [ ] Add utility functions to `ploke-tui` to allow for switching the utilized embedding model, 
  - and change from remote to local,
  - and to check the status of the currently selected embedding,
  - whether the database has already been indexed and using which embedding model

Nice-to-haves
- [ ] Add a metadata item to the database that we can use to track the behavior of embedding processing, so the user can reference which embeddings are faster/slower
- [ ] Track the cost of the embedding (for remote embeddings)
- [ ] In-app entry of API key used for remote embedding services (never written, kept in-memory unless explicitly saved by user) from `ploke-tui`

## On embeddings

### new schema needed for `embeddings` relation
New relation for `embeddings` should have at least the following fields
  - minimal identifying data points to serve as key:
    - model used for embedding
    - provider of model (e.g. from OpenAI embeddings endpoint, etc)
    - dims of vector
    - the vector itself (stored as a `<F32; N>`, where `N` is the length of the vector, and the `<>` braces are Cozo's way of specifying a special Vector type (separate from Rust Vectors, more like arrays) due to Cozo's native hnsw requirements)
  - some other metadata might be useful to include as well, such as:
    - `at` field for Cozo's Validity type (for cozo's time-travel)
      - see example of how this is used in a macro in `ploke/crates/ingest/ploke-transform/src/schema/mod.rs`
    - whether it was locally or remotely generated



### schema of code items

Before supporting multiple embeddings, we have:
```rust
// ploke/crates/ingest/ploke-transform/src/schema/primary_nodes.rs
define_schema!(FunctionNodeSchema {
    "function",
    id: "Uuid",
    name: "String",
    docstring: "String?",
    vis_kind: "String",
    vis_path: "[String]?",
    span: "[Int; 2]",
    tracking_hash: "Uuid",
    cfgs: "[String]",
    return_type_id: "Uuid?",
    body: "String?",
    module_id: "Uuid",
    embedding: "<F32; 384>?"
});
```

- We will need to change the `embedding` field to something like:
```rust
    embedding: "[(String, Int)]",
```

Where the `String` is the model identifier, e.g. `sentence-transformers/all-MiniLM-L6-v2` (subject to change, may be different depending on how the embeddings API endpoints handle them, but this looks like a reasonable naming style). The `Int` will be the dims, for example `384`, so for our locally processed embeddings with sentence-transformers this would be:
```CozoScript
[("sentence-transformers/all-MiniLM-L6-v2", 384)]
```

There are several other schema in the same directory which are similar, and other files in the same directory that may also need to be updated

### hnsw indexing

The `embedding` field is used to generate the Cozo hnsw index:
```rust
// in ploke/crates/ploke-db/src/index/hnsw.rs
    let script = [
        r#"
            ::hnsw create "#,
        ty.relation_str(),
        HNSW_SUFFIX,
        r#" {
                fields: [embedding],
                dim: 384,
                dtype: F32,
                m: 32,
                ef_construction: 200,
                distance: L2
            }
            "#,
    ]
```

As can be seen from the above cozo script, the dimensions are hardcoded as being 384, which we need to change to make variable. So we will need to add a step before creating the embedding, either in the same function or a db helper, to check the state for the selected vector embedding and dimension, then verify that the code item nodes have those embeddings in the new `embeddings` field, then retrieve those embeddings.

We can probably get the embeddings and the nodes as part of a single search, with something like:

Before:
```rust
// ploke/crates/ploke-db/src/index/hnsw.rs
    let base_script_start = r#"
    parent_of[child, parent] := *syntax_edge{source_id: parent, target_id: child, relation_kind: "Contains" @ 'NOW'}

    ancestor[desc, asc] := parent_of[desc, asc]
    ancestor[desc, asc] := parent_of[desc, intermediate], ancestor[intermediate, asc]

    has_embedding[id, name, hash, span] := *"#;
    let base_script_end = r#" {id, name, tracking_hash: hash, span, embedding @ 'NOW' }, !is_null(embedding)

    is_root_module[id] := *module{id @ 'NOW' }, *file_mod {owner_id: id @ 'NOW'}

    batch[id, name, file_path, file_hash, hash, span, namespace] := 
        has_embedding[id, name, hash, span],
        ancestor[id, mod_id],
        is_root_module[mod_id],
        *module{id: mod_id, tracking_hash: file_hash @ 'NOW'},
        *file_mod { owner_id: mod_id, file_path, namespace @ 'NOW'},

    ?[id, name, file_path, file_hash, hash, span, namespace, distance] := 
        batch[id, name, file_path, file_hash, hash, span, namespace],
     "#;
```

After (note: speculative and untested script, ideation value only):
```rust
    let base_script_start = r#"
    parent_of[child, parent] := *syntax_edge{source_id: parent, target_id: child, relation_kind: "Contains" @ 'NOW'}

    ancestor[desc, asc] := parent_of[desc, asc]
    ancestor[desc, asc] := parent_of[desc, intermediate], ancestor[intermediate, asc]

    has_embedding[id, name, hash, span, embedding_model, embedding_dims] := *"#;
    let base_script_end = r#" {id, name, tracking_hash: hash, span, embedding @ 'NOW' }, !is_null(embedding),
      *embedding { node_id: id, embedding_model, embedding_dims @ 'NOW' },

    is_root_module[id] := *module{id @ 'NOW' }, *file_mod {owner_id: id @ 'NOW'}

    batch[id, name, file_path, file_hash, hash, span, namespace, embedding_model, embedding_dims] := 
        has_embedding[id, name, hash, span, embedding_model, embedding_dims],
        ancestor[id, mod_id],
        is_root_module[mod_id],
        *module{id: mod_id, tracking_hash: file_hash @ 'NOW'},
        *file_mod { owner_id: mod_id, file_path, namespace @ 'NOW'},

    ?[id, name, file_path, file_hash, hash, span, namespace, distance, embedding_model, embedding_dims] := 
        batch[id, name, file_path, file_hash, hash, span, namespace],
     "#;
```

There are other places using a similar script, such as in `ploke-embed`, which will also need to be updated to use the new schema structure for embeddings when they process embeddings locally.

### Transforms from parsed code to code item nodes

The `embedding` field is currently populated with null values. This could work for us without needing to alter the current setup other than changing the name of the field from `embedding` to `embeddings`.

```rust
// ploke/crates/ingest/ploke-transform/src/transform/functions.rs
    let func_params = BTreeMap::from([
        (schema.id().to_string(), function.id.into()),
        // ("at".to_string(), "'ASSERT'".into()),
        (
            schema.name().to_string(),
            DataValue::from(function.name.as_str()),
        ),
        (schema.docstring().to_string(), docstring),
        (schema.span().to_string(), span),
        (schema.tracking_hash().to_string(), th_cozo),
        (schema.cfgs().to_string(), DataValue::List(cfgs)),
        (schema.return_type_id().to_string(), return_type_id),
        (schema.body().to_string(), body),
        // Kind of awkward, might want to visibility its own entity. Maybe just visibility
        // path?
        (schema.vis_kind().to_string(), vis_kind),
        (
            schema.vis_path().to_string(),
            vis_path.unwrap_or(DataValue::Null),
        ),
        // May remove this. Might be useful for debugging, less sure about in queries vs. the
        // `Contains` edge. Needs testing in `ploke-db`
        (schema.module_id().to_string(), module_id.into()),
        (schema.embedding().to_string(), DataValue::Null),
    ]);
```

### Semantic search functions

The current functions for semantic search assume a single embedding for each node item, likely needs to be altered.

```rust
// ploke/crates/ploke-db/src/index/hnsw.rs
pub fn search_similar_args(args: SimilarArgs) -> Result<EmbedDataVerbose, ploke_error::Error> {
    let SimilarArgs {
        db,
        vector_query,
        k,
        ef,
        ty,
        max_hits,
        radius,
    } = args;
    // rest of function, including cozo script...
}
```

Similarly, the call sites where these functions are used may also need to be adjusted, mostly in `ploke-rag`, but perhaps also in `ploke-tui` where the user's messages are transformed into embeddings (or perhaps we are just calling functions from `ploke-rag` in those locations?).

```rust
// ploke/crates/ploke-rag/src/core/mod.rs
    /// Perform a dense search using the HNSW index in the database.
    /// Returns a Vec of (snippet_id, score) pairs sorted by relevance.
    #[instrument(skip(self, query), fields(query_len = %query.len(), top_k = top_k))]
    pub async fn search(
      // embeds user message, then uses these args when doing the semantic search
            let args = SimilarArgs {
                db: &self.db,
                vector_query: &query_embedding,
                k: top_k,
                ef: params.ef, // Configurable ef value
                ty: node_type,
                max_hits,
                radius: params.radius, // Configurable radius value
            };
      // the rest of the search function...
    }
```

There are likely other places in `ploke-rag` which will need to be updated as well, but these will likely be mostly superficial as opposed to structural changes

There is also a function in `ploke-tui` that will need attention:
```rust
// ploke/crates/ploke-tui/src/app_state/database.rs

/// Returns a vector of batch results containing prompt indices, original prompts,
/// and their corresponding code snippets found through semantic search.
/// Results are automatically written to the specified output file as JSON.
pub(super) async fn batch_prompt_search(
    state: &Arc<AppState>,
    prompt_file: String,
    out_file: String,
    max_hits: Option<usize>,
    threshold: Option<f32>,
) -> color_eyre::Result<Vec<BatchResult>> {
    // more
}
```
